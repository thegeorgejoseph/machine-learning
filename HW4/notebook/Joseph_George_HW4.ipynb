{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809e6a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "import sklearn as sks\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128c413c",
   "metadata": {},
   "source": [
    "## Getting the Training and Testing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8518f15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances 88\n",
      "Number of testing instances 19\n",
      "Number of training instances 69\n"
     ]
    }
   ],
   "source": [
    "#sitting dataset 8 row 54\n",
    "folders = {\n",
    "    'bending1': 7,\n",
    "    'bending2': 6,\n",
    "    'cycling': 15,\n",
    "    'lying' : 15,\n",
    "    'sitting': 15,\n",
    "    'standing': 15,\n",
    "    'walking': 15  \n",
    "}\n",
    "testing_paths = []\n",
    "training_paths = []\n",
    "ordered_paths = []\n",
    "for activity, _max in folders.items():\n",
    "    for i in range(1, _max + 1):\n",
    "        ordered_paths.append((f'../data/{activity}/dataset{i}.csv', activity))\n",
    "        if i <= 2:\n",
    "            testing_paths.append(f'../data/{activity}/dataset{i}.csv')    \n",
    "        elif i == 3 and activity not in ['bending1', 'bending2']:\n",
    "            testing_paths.append(f'../data/{activity}/dataset{i}.csv')\n",
    "        else:\n",
    "            training_paths.append(f'../data/{activity}/dataset{i}.csv')\n",
    "            \n",
    "columns = ['avg_rss12', 'var_rss12', 'avg_rss13', 'var_rss13', 'avg_rss23', 'var_rss23']\n",
    "testing_dfs = [pd.read_csv(path, skiprows = 4).iloc[:, 1:] for path in testing_paths]\n",
    "training_dfs = []\n",
    "for i, path in enumerate(training_paths):\n",
    "    if path == f'../data/bending2/dataset4.csv':\n",
    "        df = pd.read_csv(f'../data/bending2/dataset4.csv', skiprows = 5, delimiter = ' ', index_col = False, names = ['time','avg_rss12','var_rss12','avg_rss13','var_rss13','avg_rss23','var_rss23']).iloc[:, 1:]\n",
    "    else:\n",
    "        df = pd.read_csv(path, skiprows=4).iloc[:, 1:]\n",
    "#         if i == 37:\n",
    "#             print(df.describe())\n",
    "    training_dfs.append(df)\n",
    "\n",
    "\n",
    "print(f\"Number of instances {len(testing_dfs) + len(training_dfs)}\")\n",
    "print(f\"Number of testing instances {len(testing_dfs)}\")\n",
    "print(f\"Number of training instances {len(training_dfs)}\")\n",
    "\n",
    "# for i, df in enumerate(training_dfs):\n",
    "#     print(i, df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06585e71",
   "metadata": {},
   "source": [
    "# 2. Time Series Classification Part 2: Binary and Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfee5eb",
   "metadata": {},
   "source": [
    "## (a) Binary Classification Using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8b58a1",
   "metadata": {},
   "source": [
    "### i. Assume that you want to use the training set to classify bending from other activities, i.e. you have a binary classification problem. Depict scatter plots of the features you specified in 1(c)iv extracted from time series 1, 2, and 6 of each instance, and use color to distinguish bending vs. other activities. (See p. 129 of the textbook).4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878f4af3",
   "metadata": {},
   "source": [
    "cols = ['Mean_1', 'Q1_1', 'Q3_1', 'Mean_2', 'Q1_2', 'Q3_2', 'Mean_6', 'Q1_6', 'Q3_6', 'Label']\n",
    "column_nums = [1,2,6] # take col - 1 for proper indexing\n",
    "rows = []\n",
    "for df, path in zip(training_dfs, training_paths):\n",
    "    label = path.split('/')[2]\n",
    "    if 'bending' in label:\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "    row = []\n",
    "    for val in column_nums:\n",
    "        row.append(df[df.columns[val-1]].astype(float).mean())\n",
    "        row.append(df[df.columns[val-1]].astype(float).quantile(0.25))\n",
    "        row.append(df[df.columns[val-1]].astype(float).quantile(0.75))\n",
    "    row.append(label)\n",
    "    rows.append(row)\n",
    "scatter_df = pd.DataFrame(rows, columns = cols)\n",
    "sns.pairplot(scatter_df, vars = scatter_df.columns[:-1], hue=\"Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfba3d2",
   "metadata": {},
   "source": [
    "### ii. Break each time series in your training set into two (approximately) equal length time series. Now instead of 6 time series for each of the training instances, you have 12 time series for each training instance. Repeat the experiment in 2(a)i, i.e depict scatter plots of the features extracted from both parts of the time series 1,2, and 6. Do you see any considerable difference in the results with those of 2(a)i?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab97be56",
   "metadata": {},
   "source": [
    "cols = ['Mean_1_first', 'Mean_1_second', 'Q1_1_first', 'Q1_1_second', 'Q3_1_first', 'Q3_1_second', 'Mean_2_first', 'Mean_2_second', 'Q1_2_first', 'Q1_2_second', 'Q3_2_first', 'Q3_2_second', 'Mean_6_first', 'Mean_6_second', 'Q1_6_first', 'Q1_6_second', 'Q3_6_first', 'Q3_6_second', 'Label']\n",
    "column_nums = [1,2,6] # take col - 1 for proper indexing\n",
    "rows = []\n",
    "for df, path in zip(training_dfs, training_paths):\n",
    "    label = path.split('/')[2]\n",
    "    half = len(df) // 2\n",
    "    if 'bending' in label:\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "    row = []\n",
    "    for val in column_nums:\n",
    "        current = np.reshape(df.iloc[:,val-1].astype(float).values, (-1,1))\n",
    "        row.append(current[:half].mean())\n",
    "        row.append(current[half:].mean())\n",
    "        row.append(np.percentile(current[:half], 25, method = 'midpoint'))\n",
    "        row.append(np.percentile(current[half:], 25, method = 'midpoint'))\n",
    "        row.append(np.percentile(current[:half], 75, method = 'midpoint'))\n",
    "        row.append(np.percentile(current[half:], 75, method = 'midpoint'))\n",
    "    row.append(float(label))\n",
    "    rows.append(row)\n",
    "\n",
    "scatter_df = pd.DataFrame(rows, columns = cols)\n",
    "sns.pairplot(scatter_df, vars = scatter_df.columns[:-1], hue=\"Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd7a895",
   "metadata": {},
   "source": [
    "### iii. Break each time series in your training set into l âˆˆ {1, 2, . . . , 20} time series of approximately equal length and use logistic regression5 to solve the binary classification problem, using time-domain features. Remember that breaking each of the time series does not change the number of instances. It only changes the number of features for each instance. Calculate the p-values for your logistic regression parameters in each model corresponding to each value of l and refit a logistic regression model using your pruned set of features.6 Alternatively, you can use backward selection using sklearn.feature selection or glm in R. Use 5-fold cross-validation to determine the best value of the pair (l, p), where p is the number of features used in recursive feature elimination. Explain what the right way and the wrong way are to perform cross-validation in this problem.7 Obviously, use the right way! Also, you may encounter the problem of class imbalance, which may make some of your folds not having any instances of the rare class. In such a case, you can use stratified cross validation. Research what it means and use it if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7822328f",
   "metadata": {},
   "source": [
    "column_nums = [1,2,3,4,5,6] # take col - 1 for proper indexing\n",
    "best_score = float('-inf') \n",
    "for l in range(1, 21):\n",
    "    rows = []\n",
    "    for df, path in zip(training_dfs, training_paths):\n",
    "        size = math.ceil(len(df) / l)\n",
    "        label = path.split('/')[2]\n",
    "        if 'bending' in label:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        row = []\n",
    "        column_names = []\n",
    "        for val in column_nums:\n",
    "            start = 0\n",
    "            part = 1\n",
    "#             current = np.reshape(df.iloc[:,val-1].astype(float).values, (-1,1))\n",
    "            while start < len(df):\n",
    "#                 row.append(current[start:start+size].mean())\n",
    "                row.append(df[df.columns[val-1]].iloc[start:(start+size)].astype(float).mean())\n",
    "                column_names.append(f'Mean_{val}_{part}')\n",
    "#                 row.append(np.percentile(current[start:start+size], 25, method = 'midpoint'))\n",
    "                row.append(df[df.columns[val-1]].iloc[start:(start+size)].astype(float).quantile(0.25))\n",
    "                column_names.append(f'Q1_{val}_{part}')\n",
    "#                 row.append(np.percentile(current[start: start + size], 75, method = 'midpoint'))\n",
    "                row.append(df[df.columns[val-1]].iloc[start:(start+size)].astype(float).quantile(0.75))\n",
    "                column_names.append(f'Q3_{val}_{part}')\n",
    "                start = start + size\n",
    "                part += 1\n",
    "        row.append(label)\n",
    "        rows.append(row[:])\n",
    "        \n",
    "    column_names.append('Label')\n",
    "    logr_df = pd.DataFrame(rows, columns = column_names)\n",
    "    logit = LogisticRegression(penalty='none')\n",
    "    rfecv = RFECV(estimator=logit,cv=StratifiedKFold(5))\n",
    "    model = rfecv.fit(logr_df.iloc[:,:-1], logr_df.iloc[:,-1])\n",
    "    if max(model.cv_results_['mean_test_score']) > best_score:\n",
    "        best_score = max(model.cv_results_['mean_test_score'])\n",
    "        best_model = model\n",
    "        best_params = model.get_feature_names_out()\n",
    "        best_l = l\n",
    "        best_train_df = logr_df.copy()\n",
    "\n",
    "print(f'Best l is {best_l}')\n",
    "print(f'Best params are {best_params}')\n",
    "print(max(best_model.cv_results_['mean_test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221eda98",
   "metadata": {},
   "source": [
    "### iv. Report the confusion matrix and show the ROC and AUC for your classifier on train data. Report the parameters of your logistic regression Î²iâ€™s as well as the p-values associated with them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e146f73c",
   "metadata": {},
   "source": [
    "y_train_best = best_train_df.iloc[:,-1]\n",
    "X_train_best = best_train_df[best_params].copy()\n",
    "pred = best_model.predict(best_train_df.iloc[:,:-1])\n",
    "cm=metrics.confusion_matrix(y_train_best,pred)\n",
    "print(cm)\n",
    "metrics.plot_roc_curve(best_model, best_train_df.iloc[:,:-1], best_train_df.iloc[:,-1])\n",
    "log_reg = sm.Logit(y_train_best, X_train_best).fit(method='lbfgs')\n",
    "print(log_reg.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209b9319",
   "metadata": {},
   "source": [
    "### v. Test the classifier on the test set. Remember to break the time series in your test set into the same number of time series into which you broke your training set. Remember that the classifier has to be tested using the features extracted from the test set. Compare the accuracy on the test set with the cross-validation accuracy you obtained previously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4ce2f3",
   "metadata": {},
   "source": [
    "rows = []\n",
    "for df, path in zip(testing_dfs, testing_paths):\n",
    "    size = math.ceil(len(df) / best_l)\n",
    "    label = path.split('/')[2]\n",
    "    if 'bending' in label:\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "    row = []\n",
    "    column_names = []\n",
    "    for val in column_nums:\n",
    "        start = 0\n",
    "        part = 1\n",
    "        current = np.reshape(df.iloc[:,val-1].astype(float).values, (-1,1))\n",
    "        while start < len(df):\n",
    "#                 row.append(current[start:start+size].mean())\n",
    "            row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).mean())\n",
    "            column_names.append(f'Mean_{val}_{part}')\n",
    "#                 row.append(np.percentile(current[start:start+size], 25, method = 'midpoint'))\n",
    "            row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).quantile(0.25))\n",
    "            column_names.append(f'Q1_{val}_{part}')\n",
    "#                 row.append(np.percentile(current[start: start + size], 75, method = 'midpoint'))\n",
    "            row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).quantile(0.75))\n",
    "            column_names.append(f'Q3_{val}_{part}')\n",
    "            start = start + size\n",
    "            part += 1\n",
    "    row.append(label)\n",
    "    rows.append(row[:])\n",
    "\n",
    "column_names.append('Label')\n",
    "test_df = pd.DataFrame(rows, columns = column_names)\n",
    "test_df.shape\n",
    "\n",
    "X_test_df = test_df.iloc[:,:-1]\n",
    "y_test_df = test_df.iloc[:, -1]\n",
    "preds = best_model.predict(X_test_df)\n",
    "score = best_model.score(X_test_df, y_test_df)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b2e2fa",
   "metadata": {},
   "source": [
    "### vi. Do your classes seem to be well-separated to cause instability in calculating logistic regression parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df759bce",
   "metadata": {},
   "source": [
    "Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a971eee4",
   "metadata": {},
   "source": [
    "### vii. From the confusion matrices you obtained, do you see imbalanced classes? If yes, build a logistic regression model based on case-control sampling and adjust its parameters. Report the confusion matrix, ROC, and AUC of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fefe8f8",
   "metadata": {},
   "source": [
    "cm=metrics.confusion_matrix(y_test_df,preds)\n",
    "print(cm)\n",
    "metrics.plot_roc_curve(best_model, X_test_df, y_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f567681",
   "metadata": {},
   "source": [
    "column_nums = [1,2,3,4,5,6] # take col - 1 for proper indexing\n",
    "cc_best_score = float('-inf')\n",
    "oversample = BorderlineSMOTE(random_state = 101, kind = 'borderline-1')\n",
    "for l in range(1, 21):\n",
    "    rows = []\n",
    "    for df, path in zip(training_dfs, training_paths):\n",
    "        size = math.ceil(len(df) / l)\n",
    "        label = path.split('/')[2]\n",
    "        if 'bending' in label:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        row = []\n",
    "        column_names = []\n",
    "        for val in column_nums:\n",
    "            start = 0\n",
    "            part = 1\n",
    "            while start < len(df):\n",
    "                row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).mean())\n",
    "                column_names.append(f'Mean_{val}_{part}')\n",
    "                row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).quantile(0.25))\n",
    "                column_names.append(f'Q1_{val}_{part}')\n",
    "                row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).quantile(0.75))\n",
    "                column_names.append(f'Q3_{val}_{part}')\n",
    "                start = start + size\n",
    "                part += 1\n",
    "        row.append(label)\n",
    "        rows.append(row[:])\n",
    "        \n",
    "    column_names.append('Label')\n",
    "    logr_df = pd.DataFrame(rows, columns = column_names)\n",
    "    logit = LogisticRegression(penalty='none')\n",
    "    rfecv = RFECV(estimator=logit,cv=StratifiedKFold(5))\n",
    "    X, y = oversample.fit_resample(logr_df.iloc[:,:-1], logr_df.iloc[:,-1])\n",
    "    model = rfecv.fit(X,y)\n",
    "    if max(model.cv_results_['mean_test_score']) > cc_best_score:\n",
    "        cc_best_score = max(model.cv_results_['mean_test_score'])\n",
    "        cc_best_model = model\n",
    "        cc_best_params = model.get_feature_names_out()\n",
    "        cc_best_l = l\n",
    "        cc_best_train_df = X.copy()\n",
    "\n",
    "print(f'Best l is {cc_best_l}')\n",
    "print(f'Best params are {cc_best_params}')\n",
    "print(max(cc_best_model.cv_results_['mean_test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dfc837",
   "metadata": {},
   "source": [
    "rows = []\n",
    "for df, path in zip(testing_dfs, testing_paths):\n",
    "    size = math.ceil(len(df) / cc_best_l)\n",
    "    label = path.split('/')[2]\n",
    "    if 'bending' in label:\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "    row = []\n",
    "    column_names = []\n",
    "    for val in column_nums:\n",
    "        start = 0\n",
    "        part = 1\n",
    "        current = np.reshape(df.iloc[:,val-1].astype(float).values, (-1,1))\n",
    "        while start < len(df):\n",
    "            row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).mean())\n",
    "            column_names.append(f'Mean_{val}_{part}')\n",
    "            row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).quantile(0.25))\n",
    "            column_names.append(f'Q1_{val}_{part}')\n",
    "            row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).quantile(0.75))\n",
    "            column_names.append(f'Q3_{val}_{part}')\n",
    "            start = start + size\n",
    "            part += 1\n",
    "    row.append(label)\n",
    "    rows.append(row[:])\n",
    "\n",
    "column_names.append('Label')\n",
    "test_df = pd.DataFrame(rows, columns = column_names)\n",
    "test_df.shape\n",
    "\n",
    "X_test_df = test_df.iloc[:,:-1]\n",
    "y_test_df = test_df.iloc[:, -1]\n",
    "preds = cc_best_model.predict(X_test_df)\n",
    "score = cc_best_model.score(X_test_df, y_test_df)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc9052b",
   "metadata": {},
   "source": [
    "cm=metrics.confusion_matrix(y_test_df,preds)\n",
    "print(cm)\n",
    "metrics.plot_roc_curve(cc_best_model,X_test_df, y_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b015ea",
   "metadata": {},
   "source": [
    "## (b) Binary Classification Using L1-penalized logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f54a43",
   "metadata": {},
   "source": [
    "### i. Repeat 2(a)iii using L1-penalized logistic regression,8 i.e. instead of using p- values for variable selection, use L1 regularization. Note that in this problem, you have to cross-validate for both l, the number of time series into which you break each of your instances, and Î», the weight of L1 penalty in your logistic regression objective function (or C, the budget). Packages usually perform cross-validation for Î» automatically.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29238d12",
   "metadata": {},
   "source": [
    "column_nums = [1,2,3,4,5,6] # take col - 1 for proper indexing\n",
    "l1_best_score = float('-inf') \n",
    "for l in range(1, 21):\n",
    "    rows = []\n",
    "    for df, path in zip(training_dfs, training_paths):\n",
    "        size = math.ceil(len(df) / l)\n",
    "        label = path.split('/')[2]\n",
    "        if 'bending' in label:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        row = []\n",
    "        column_names = []\n",
    "        for val in column_nums:\n",
    "            start = 0\n",
    "            part = 1\n",
    "            while start < len(df):\n",
    "                row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).mean())\n",
    "                column_names.append(f'Mean_{val}_{part}')\n",
    "                row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).quantile(0.25))\n",
    "                column_names.append(f'Q1_{val}_{part}')\n",
    "                row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).quantile(0.75))\n",
    "                column_names.append(f'Q3_{val}_{part}')\n",
    "                start = start + size\n",
    "                part += 1\n",
    "        row.append(label)\n",
    "        rows.append(row[:])\n",
    "        \n",
    "    column_names.append('Label')\n",
    "    logr_df = pd.DataFrame(rows, columns = column_names)\n",
    "    logit = LogisticRegressionCV(solver='liblinear',penalty='l1', cv=StratifiedKFold(5), random_state=0)\n",
    "    model = logit.fit(logr_df.iloc[:,:-1], logr_df.iloc[:,-1])\n",
    "    score = np.max(np.mean(model.scores_[1], axis = 0))\n",
    "    if score > l1_best_score:\n",
    "        l1_best_score = score\n",
    "        l1_best_model = model\n",
    "#         l1_best_params = model.get_feature_names_out()\n",
    "        l1_best_c = model.C_\n",
    "        l1_best_l = l\n",
    "        l1_best_train_df = logr_df.copy()\n",
    "\n",
    "print(f'Best l is {l1_best_l}')\n",
    "print(f'Best Cs are {l1_best_c}')\n",
    "print(l1_best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec6243e",
   "metadata": {},
   "source": [
    "rows = []\n",
    "for df, path in zip(testing_dfs, testing_paths):\n",
    "    size = math.ceil(len(df) / l1_best_l)\n",
    "    label = path.split('/')[2]\n",
    "    if 'bending' in label:\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "    row = []\n",
    "    column_names = []\n",
    "    for val in column_nums:\n",
    "        start = 0\n",
    "        part = 1\n",
    "        current = np.reshape(df.iloc[:,val-1].astype(float).values, (-1,1))\n",
    "        while start < len(df):\n",
    "            row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).mean())\n",
    "            column_names.append(f'Mean_{val}_{part}')\n",
    "            row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).quantile(0.25))\n",
    "            column_names.append(f'Q1_{val}_{part}')\n",
    "            row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).quantile(0.75))\n",
    "            column_names.append(f'Q3_{val}_{part}')\n",
    "            start = start + size\n",
    "            part += 1\n",
    "    row.append(label)\n",
    "    rows.append(row[:])\n",
    "\n",
    "column_names.append('Label')\n",
    "test_df = pd.DataFrame(rows, columns = column_names)\n",
    "test_df.shape\n",
    "\n",
    "X_test_df = test_df.iloc[:,:-1]\n",
    "y_test_df = test_df.iloc[:, -1]\n",
    "preds = l1_best_model.predict(X_test_df)\n",
    "score = l1_best_model.score(X_test_df, y_test_df)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b5bab2",
   "metadata": {},
   "source": [
    "cm=metrics.confusion_matrix(y_test_df,preds)\n",
    "print(cm)\n",
    "metrics.plot_roc_curve(l1_best_model,X_test_df, y_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c901e81",
   "metadata": {},
   "source": [
    "### ii. Compare the L1-penalized with variable selection using p-values. Which one performs better? Which one is easier to implement?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36724471",
   "metadata": {},
   "source": [
    "l1 better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edadeb9b",
   "metadata": {},
   "source": [
    "## (c) Multi-class Classification (The Realistic Case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2720d9e5",
   "metadata": {},
   "source": [
    "### i. Find the best l in the same way as you found it in 2(b)i to build an L1- penalized multinomial regression model to classify all activities in your train- ing set.10 Report your test error. Research how confusion matrices and ROC curves are defined for multiclass classification and show them for this problem if possible.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da97da18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best l is 1\n",
      "Best Cs are [166.81005372 166.81005372 166.81005372 166.81005372 166.81005372\n",
      " 166.81005372 166.81005372]\n",
      "0.8835164835164834\n"
     ]
    }
   ],
   "source": [
    "labels = {\n",
    "    'bending1': 0,\n",
    "    'bending2': 1,\n",
    "    'cycling': 2,\n",
    "    'lying' : 3,\n",
    "    'sitting': 4,\n",
    "    'standing': 5,\n",
    "    'walking': 6  \n",
    "}\n",
    "column_nums = [1,2,3,4,5,6] # take col - 1 for proper indexing\n",
    "multi_best_score = float('-inf') \n",
    "for l in range(1, 21):\n",
    "    rows = []\n",
    "    for df, path in zip(training_dfs, training_paths):\n",
    "        size = math.ceil(len(df) / l)\n",
    "        label = path.split('/')[2]\n",
    "        label = labels[label]\n",
    "        row = []\n",
    "        column_names = []\n",
    "        for val in column_nums:\n",
    "            start = 0\n",
    "            part = 1\n",
    "            while start < len(df):\n",
    "                row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).mean())\n",
    "                column_names.append(f'Mean_{val}_{part}')\n",
    "                row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).quantile(0.25))\n",
    "                column_names.append(f'Q1_{val}_{part}')\n",
    "                row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).quantile(0.75))\n",
    "                column_names.append(f'Q3_{val}_{part}')\n",
    "                start = start + size\n",
    "                part += 1\n",
    "        row.append(label)\n",
    "        rows.append(row[:])\n",
    "    \n",
    "    column_names.append('Label')\n",
    "    logr_df = pd.DataFrame(rows, columns = column_names)\n",
    "    logit = LogisticRegressionCV(solver='saga',penalty='l1', cv=StratifiedKFold(5), random_state=0, multi_class='multinomial')\n",
    "    scaler = MinMaxScaler()\n",
    "    X, y = scaler.fit_transform(logr_df.iloc[:,:-1]), logr_df.iloc[:,-1]\n",
    "    \n",
    "    model = logit.fit(X, y)\n",
    "#     print(model.scores_)\n",
    "    score = np.max(np.mean(model.scores_[1], axis = 0))\n",
    "    if score > multi_best_score:\n",
    "        multi_best_score = score\n",
    "        multi_best_model = model\n",
    "        multi_best_c = model.C_\n",
    "        multi_best_l = l\n",
    "        multi_best_train_df = X.copy()\n",
    "        multi_scaler = scaler\n",
    "\n",
    "print(f'Best l is {multi_best_l}')\n",
    "print(f'Best Cs are {multi_best_c}')\n",
    "print(multi_best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d24a25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "4\n",
      "12\n",
      "12\n",
      "13\n",
      "11\n",
      "12\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQdUlEQVR4nO3df2xdZ33H8fcXJxFYAUpiE1hc5jClpvmjnYoJaIwRxhhJ9kdUCYkWRLUIFKpRxB9IazVpVBP/wFAlhAhEUZVU/ENQRzvCZFINTaWoXWndqqRNI0deWhoT1jqk/Gijkrr97g9fuhvH9j12ju/1ffx+SVe65znPOff71NYnT4/veU5kJpKk7ve6ThcgSaqHgS5JhTDQJakQBrokFcJAl6RCrOrUB/f19eXg4GCnPl6SutIjjzxyJjP7Z9vXsUAfHBxkdHS0Ux8vSV0pIn4x1z4vuUhSIQx0SSqEgS5JhTDQJakQBrokFaJloEfEgYh4LiKemGN/RMQ3ImI8Io5GxDX1lylJaqXKDP0OYPs8+3cAmxuvPcC3L70sSdJCtfweembeFxGD83TZBXwnp9fhfTAiLouIt2fmr+oqstmT//iv9P5+/VKcui3+0NPDH17XU6lvNl5VZfRAdOzWAkkV/e7l5/ng3s/Wft46rqFvBE41bU802i4SEXsiYjQiRicnJxf1Yb2/X09P78Cijl0O/vC6Hl6JqNR3wSvVxyqSaueWVJ46pnOzJcisWZSZ+4H9AMPDw4t+ssYr5yYY/PanF3t4R33vX24B4OO3fqVl391HdgNwcPvBSue++7ZHAbj2i/4ZQ1qJ6pihTwCXN20PAKdrOK8kaQHqCPTDwA2Nb7u8D/jtUl0/lyTNreUll4j4LrAN6IuICeBWYDVAZu4DRoCdwDhwDti9VMVKkuZW5Vsu17fYn8DnaqtIkrQo3ikqSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoRrrXapYz/9JSceevaCtjMTL9A3sLZDFUnqNGfoXerEQ89yZuKFC9r6BtZyxdYNHapIUqc5Q1+gO0/cycjJkUUfv+nsb4D/Xxp3PmNnxxhaNzTn/r6BtS6VK+k1RQf60R8f4fj999Z6zrGzY2x4+Ry9q3sXdfzrz07x0rpq/9mH1g2x8507F/U5klaeogP9+P33Mvn0U/QPbqr1vL2re+edOc9rHVz5/m1c9TfzPaZVkhau6EAH6B/cVOnpQFX98VLJl7bXd05JqoN/FJWkQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUiOJv/e92s617Dq59LuliztCXudnWPQfXPpd0MWfoXcB1zyVV4QxdkgphoEtSIQx0SSqEgS5JhagU6BGxPSLGImI8Im6ZZf+bI+KHEfHziDgWEa2fgCxJqlXLQI+IHmAvsAPYAlwfEVtmdPsc8GRmXg1sA26LiDU11ypJmkeVGfpWYDwzT2bmeeAQsGtGnwTeGBEBrAXOAlO1VipJmleVQN8InGranmi0NfsmcCVwGngc+EJmvjrzRBGxJyJGI2J0cnJykSVLkmZTJdBjlracsf1R4DHgT4A/B74ZEW+66KDM/Zk5nJnD/f39CyxVkjSfKoE+AVzetD3A9Ey82W7grpw2DjwFvKueEiVJVVQJ9IeBzRGxqfGHzuuAwzP6PAN8GCAiNgBDwMk6C5Ukza/lWi6ZORURNwH3AD3Agcw8FhE3NvbvA74M3BERjzN9iebmzDyzhHVLkmaotDhXZo4AIzPa9jW9Pw38bb2lSZIWwjtFJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqRDEPiT764yMcv//eC9omn36K/sFNnSlIktqsmBn68fvvZfLppy5o6x/cxJXv39aZgiSpzYqZocN0gH/81q90ugxJ6ohiZuiStNIZ6JJUCANdkgphoEtSIYr6o+hydOynv+TEQ88u+vgzEy/QN7C2xooklcoZ+hI78dCznJl4YdHH9w2s5YqtG2qsSFKpnKG3Qd/AWq794jWdLkNS4ZyhS1IhDHRJKsSKu+Ry54k7GTk50rrjHMbOjjG0bqjGiiSpHituhj5ycoSxs2OLPn5o3RA737mzxookqR4rboYO06F8cPvBTpchSbVacTN0SSqVgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKsSK/hz6bS13mdi4ufyupXSrN0CNie0SMRcR4RNwyR59tEfFYRByLiJ/UW+bSu9Rlbufi8reS2qXlDD0ieoC9wEeACeDhiDicmU829bkM+BawPTOfiYi3LlG9S8plbiV1syoz9K3AeGaezMzzwCFg14w+nwDuysxnADLzuXrLlCS1UiXQNwKnmrYnGm3NrgDeEhH3RsQjEXHDbCeKiD0RMRoRo5OTk4urWJI0qyqBHrO05YztVcC7gb8DPgr8c0RccdFBmfszczgzh/v7+xdcrCRpblW+5TIBXN60PQCcnqXPmcx8EXgxIu4DrgZO1FKlJKmlKjP0h4HNEbEpItYA1wGHZ/T5AfCBiFgVEb3Ae4Hj9ZYqSZpPyxl6Zk5FxE3APUAPcCAzj0XEjY39+zLzeEQcAY4CrwK3Z+YTS1m4JOlClW4syswRYGRG274Z218DvlZfaZKkhfDWf0kqhIEuSYUw0CWpEAa6JBXCQJekQqzI5XP7nt7M3bc9ekGby9xK6nYrcoa+/tTgRUvlusytpG63Imfo4FK5ksqzImfoklQiA12SCmGgS1IhDHRJKoSBLkmFKOZbLpPnJjn70ll2H9k9b7+xs2MM8ZE2VSVJ7VPMDP3sS2c59/K5lv2G1g2x7g3r21CRJLVXMTN0gN7VvRzcfrBlv7uPPdqyjyR1m2Jm6JK00hnoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQlQI9IrZHxFhEjEfELfP0e09EvBIRH6uvRElSFS0DPSJ6gL3ADmALcH1EbJmj31eBe+ouUpLUWpUZ+lZgPDNPZuZ54BCwa5Z+nwe+DzxXY32SpIqqBPpG4FTT9kSj7TURsRG4Ftg334kiYk9EjEbE6OTk5EJrlSTNo0qgxyxtOWP768DNmfnKfCfKzP2ZOZyZw/39/RVLlCRVUeUh0RPA5U3bA8DpGX2GgUMRAdAH7IyIqcz89zqKlCS1ViXQHwY2R8Qm4JfAdcAnmjtk5qY/vo+IO4D/MMwlqb1aBnpmTkXETUx/e6UHOJCZxyLixsb+ea+bS5Lao8oMncwcAUZmtM0a5Jn595deliRpobxTVJIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFWJVpwtYqKmAqUh2H9l9QfuGl8/Ru7q3Q1VJUud13Qx9KpJXZ2nvXd3Luteva3s9krRcdN0MHab/FTq4/eAFbd/72S2dKUaSlomum6FLkmZnoEtSIQx0SSqEgS5JhTDQJakQlQI9IrZHxFhEjEfERV8niYhPRsTRxuuBiLi6/lIlSfNpGegR0QPsBXYAW4DrI2LLjG5PAR/MzKuALwP76y5UkjS/KjP0rcB4Zp7MzPPAIWBXc4fMfCAzn29sPggM1FumJKmVKoG+ETjVtD3RaJvLp4EfzbYjIvZExGhEjE5OTlavUpLUUpVAj1nactaOER9iOtBvnm1/Zu7PzOHMHO7v769epSSppSq3/k8AlzdtDwCnZ3aKiKuA24EdmfnresqTJFVVZYb+MLA5IjZFxBrgOuBwc4eIeAdwF/CpzDxRf5mSpFZaztAzcyoibgLuAXqAA5l5LCJubOzfB3wJWA98KyIApjJzeOnKliTNVGm1xcwcAUZmtO1rev8Z4DP1liZJWgjvFJWkQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRCVAj0itkfEWESMR8Qts+yPiPhGY//RiLim/lIlSfNpGegR0QPsBXYAW4DrI2LLjG47gM2N1x7g2zXXKUlqYVWFPluB8cw8CRARh4BdwJNNfXYB38nMBB6MiMsi4u2Z+au6C35p1ZvIgL2fuemC9vPn/pc1vW/j7tsebXmOMxMv0Dewtu7SJKmjqlxy2QicatqeaLQttA8RsSciRiNidHJycqG1AvDbqef5zflfX9S+pvdtrF1/VaVz9A2s5YqtGxb1+ZK0XFWZoccsbbmIPmTmfmA/wPDw8EX7q/jg3s8C8KHFHCxJBasyQ58ALm/aHgBOL6KPJGkJVQn0h4HNEbEpItYA1wGHZ/Q5DNzQ+LbL+4DfLsX1c0nS3FpecsnMqYi4CbgH6AEOZOaxiLixsX8fMALsBMaBc8DupStZkjSbKtfQycwRpkO7uW1f0/sEPldvaZKkhfBOUUkqhIEuSYUw0CWpEAa6JBUipv+e2YEPjpgEfrHIw/uAMzWW0w0c88rgmFeGSxnzn2Zm/2w7OhbolyIiRjNzuNN1tJNjXhkc88qwVGP2koskFcJAl6RCdGug7+90AR3gmFcGx7wyLMmYu/IauiTpYt06Q5ckzWCgS1IhlnWgr8SHU1cY8ycbYz0aEQ9ExNWdqLNOrcbc1O89EfFKRHysnfUthSpjjohtEfFYRByLiJ+0u8a6VfjdfnNE/DAift4Yc1ev2hoRByLiuYh4Yo799edXZi7LF9NL9f4P8E5gDfBzYMuMPjuBHzH9xKT3AT/rdN1tGPNfAG9pvN+xEsbc1O+/mF7182OdrrsNP+fLmH5u7zsa22/tdN1tGPM/AV9tvO8HzgJrOl37JYz5r4BrgCfm2F97fi3nGfprD6fOzPPAHx9O3ey1h1Nn5oPAZRHx9nYXWqOWY87MBzLz+cbmg0w/HaqbVfk5A3we+D7wXDuLWyJVxvwJ4K7MfAYgM7t93FXGnMAbIyKAtUwH+lR7y6xPZt7H9BjmUnt+LedAr+3h1F1koeP5NNP/wnezlmOOiI3AtcA+ylDl53wF8JaIuDciHomIG9pW3dKoMuZvAlcy/fjKx4EvZOar7SmvI2rPr0oPuOiQ2h5O3UUqjyciPsR0oP/lkla09KqM+evAzZn5yvTkretVGfMq4N3Ah4E3AP8dEQ9m5omlLm6JVBnzR4HHgL8G/gz4z4j4aWb+bolr65Ta82s5B/pKfDh1pfFExFXA7cCOzPx1m2pbKlXGPAwcaoR5H7AzIqYy89/bUmH9qv5un8nMF4EXI+I+4GqgWwO9yph3A1/J6QvM4xHxFPAu4KH2lNh2tefXcr7kshIfTt1yzBHxDuAu4FNdPFtr1nLMmbkpMwczcxD4N+AfujjModrv9g+AD0TEqojoBd4LHG9znXWqMuZnmP4/EiJiAzAEnGxrle1Ve34t2xl6rsCHU1cc85eA9cC3GjPWqezileoqjrkoVcacmccj4ghwFHgVuD0zZ/36Wzeo+HP+MnBHRDzO9OWImzOza5fVjYjvAtuAvoiYAG4FVsPS5Ze3/ktSIZbzJRdJ0gIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQ/wcAMmBzEI9/nAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = multi_best_model.predict(multi_best_train_df)\n",
    "pred_proba = multi_best_model.decision_function(multi_best_train_df).T\n",
    "# print(pred_proba)\n",
    "for i, probs in enumerate(pred_proba):\n",
    "    current_y = (preds == i).astype(int)\n",
    "    print(current_y.sum())\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(current_y, probs)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c5c96d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "#Test Data\n",
    "rows = []\n",
    "print(multi_best_l)\n",
    "for df, path in zip(testing_dfs, testing_paths):\n",
    "    size = math.ceil(len(df) / multi_best_l)\n",
    "    label = path.split('/')[2]\n",
    "    label = labels[label]\n",
    "    row = []\n",
    "    column_names = []\n",
    "    for val in column_nums:\n",
    "        start = 0\n",
    "        part = 1\n",
    "        current = np.reshape(df.iloc[:,val-1].astype(float).values, (-1,1))\n",
    "        while start < len(df):\n",
    "            row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).mean())\n",
    "            column_names.append(f'Mean_{val}_{part}')\n",
    "            row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).quantile(0.25))\n",
    "            column_names.append(f'Q1_{val}_{part}')\n",
    "            row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).quantile(0.75))\n",
    "            column_names.append(f'Q3_{val}_{part}')\n",
    "            start = start + size\n",
    "            part += 1\n",
    "    row.append(label)\n",
    "    rows.append(row[:])\n",
    "\n",
    "column_names.append('Label')\n",
    "multi_test_df = pd.DataFrame(rows, columns = column_names)\n",
    "# print(multi_test_df.shape)\n",
    "\n",
    "X_test_df_multi = multi_scaler.transform(multi_test_df.iloc[:,:-1])\n",
    "y_test_df_multi = multi_test_df.iloc[:, -1]\n",
    "preds = multi_best_model.predict(X_test_df_multi)\n",
    "score = multi_best_model.score(X_test_df_multi, y_test_df_multi)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60afcb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[2 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0]\n",
      " [0 0 3 0 0 0 0]\n",
      " [0 0 0 3 0 0 0]\n",
      " [0 0 0 0 2 1 0]\n",
      " [0 0 0 0 0 3 0]\n",
      " [0 0 0 0 0 0 3]]\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(y_test_df_multi, preds)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "# metrics.plot_roc_curve(multi_best_model, multi_best_train_df.iloc[:,:-1], multi_best_train_df.iloc[:,-1])\n",
    "pred_proba = multi_best_model.decision_function(X_test_df_multi).T\n",
    "for i, probs in enumerate(pred_proba):\n",
    "    current_y = (preds == i).astype(int)\n",
    "    print(current_y.sum())\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(current_y, probs)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr)\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa3abe7",
   "metadata": {},
   "source": [
    "### ii. Repeat 2(c)i using a Na ÌˆÄ±ve Bayesâ€™ classifier. Use both Gaussian and Multi- nomial priors and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac7293c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best l is 1\n",
      "0.7835164835164835\n"
     ]
    }
   ],
   "source": [
    "column_nums = [1,2,3,4,5,6] # take col - 1 for proper indexing\n",
    "naive_best_score = float('-inf') \n",
    "for l in range(1, 21):\n",
    "    rows = []\n",
    "    for df, path in zip(training_dfs, training_paths):\n",
    "        size = math.ceil(len(df) / l)\n",
    "        label = path.split('/')[2]\n",
    "        label = labels[label]\n",
    "        row = []\n",
    "        column_names = []\n",
    "        for val in column_nums:\n",
    "            start = 0\n",
    "            part = 1\n",
    "            while start < len(df):\n",
    "                row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).mean())\n",
    "                column_names.append(f'Mean_{val}_{part}')\n",
    "                row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).quantile(0.25))\n",
    "                column_names.append(f'Q1_{val}_{part}')\n",
    "                row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).quantile(0.75))\n",
    "                column_names.append(f'Q3_{val}_{part}')\n",
    "                start = start + size\n",
    "                part += 1\n",
    "        row.append(label)\n",
    "        rows.append(row[:])\n",
    "    \n",
    "    column_names.append('Label')\n",
    "    nb_df = pd.DataFrame(rows, columns = column_names)\n",
    "    nb = GaussianNB()\n",
    "    scaler = MinMaxScaler()\n",
    "    X, y = scaler.fit_transform(nb_df.iloc[:,:-1]), nb_df.iloc[:,-1]\n",
    "    score = cross_val_score(nb, X, y, cv = StratifiedKFold(5), scoring = 'accuracy').mean()\n",
    "    model = nb.fit(X, y)\n",
    "    if score > naive_best_score:\n",
    "        naive_best_score = score\n",
    "        naive_best_model = model\n",
    "#         multi_best_c = model.C_\n",
    "        naive_best_l = l\n",
    "        naive_best_train_df = X.copy()\n",
    "        naive_scaler = scaler\n",
    "\n",
    "print(f'Best l is {naive_best_l}')\n",
    "# print(f'Best Cs are {multi_best_c}')\n",
    "print(naive_best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfa6fb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "#Test Data\n",
    "rows = []\n",
    "for df, path in zip(testing_dfs, testing_paths):\n",
    "    size = math.ceil(len(df) / naive_best_l)\n",
    "    label = path.split('/')[2]\n",
    "    label = labels[label]\n",
    "    row = []\n",
    "    column_names = []\n",
    "    for val in column_nums:\n",
    "        start = 0\n",
    "        part = 1\n",
    "        current = np.reshape(df.iloc[:,val-1].astype(float).values, (-1,1))\n",
    "        while start < len(df):\n",
    "            row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).mean())\n",
    "            column_names.append(f'Mean_{val}_{part}')\n",
    "            row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).quantile(0.25))\n",
    "            column_names.append(f'Q1_{val}_{part}')\n",
    "            row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).quantile(0.75))\n",
    "            column_names.append(f'Q3_{val}_{part}')\n",
    "            start = start + size\n",
    "            part += 1\n",
    "    row.append(label)\n",
    "    rows.append(row[:])\n",
    "\n",
    "column_names.append('Label')\n",
    "naive_test_df = pd.DataFrame(rows, columns = column_names)\n",
    "naive_test_df.shape\n",
    "\n",
    "X_test_df_naive = naive_scaler.transform(naive_test_df.iloc[:,:-1])\n",
    "y_test_df_naive = naive_test_df.iloc[:, -1]\n",
    "preds = naive_best_model.predict(X_test_df_naive)\n",
    "score = naive_best_model.score(X_test_df_naive, y_test_df_naive)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfc96d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[2 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0]\n",
      " [0 0 3 0 0 0 0]\n",
      " [0 0 0 3 0 0 0]\n",
      " [0 0 0 0 1 2 0]\n",
      " [0 0 0 0 0 3 0]\n",
      " [0 0 0 0 0 0 3]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(y_test_df_naive, preds)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "pred_proba = naive_best_model.predict_proba(X_test_df_naive).T\n",
    "for i, probs in enumerate(pred_proba):\n",
    "#     print(probs)\n",
    "    current_y = (preds == i).astype(int)\n",
    "#     print(current_y)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(current_y, probs)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a3b5df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best l is 1\n",
      "0.810989010989011\n"
     ]
    }
   ],
   "source": [
    "column_nums = [1,2,3,4,5,6] # take col - 1 for proper indexing\n",
    "naive_best_score = float('-inf') \n",
    "for l in range(1, 21):\n",
    "    rows = []\n",
    "    for df, path in zip(training_dfs, training_paths):\n",
    "        size = math.ceil(len(df) / l)\n",
    "        label = path.split('/')[2]\n",
    "        label = labels[label]\n",
    "        row = []\n",
    "        column_names = []\n",
    "        for val in column_nums:\n",
    "            start = 0\n",
    "            part = 1\n",
    "            while start < len(df):\n",
    "                row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).mean())\n",
    "                column_names.append(f'Mean_{val}_{part}')\n",
    "                row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).quantile(0.25))\n",
    "                column_names.append(f'Q1_{val}_{part}')\n",
    "                row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).quantile(0.75))\n",
    "                column_names.append(f'Q3_{val}_{part}')\n",
    "                start = start + size\n",
    "                part += 1\n",
    "        row.append(label)\n",
    "        rows.append(row[:])\n",
    "    \n",
    "    column_names.append('Label')\n",
    "    nb_df = pd.DataFrame(rows, columns = column_names)\n",
    "    nb = MultinomialNB()\n",
    "    score = cross_val_score(nb, nb_df.iloc[:,:-1], nb_df.iloc[:,-1], cv = StratifiedKFold(5), scoring = 'accuracy').mean()\n",
    "    model = nb.fit(nb_df.iloc[:,:-1], nb_df.iloc[:,-1])\n",
    "    if score > naive_best_score:\n",
    "        naive_best_score = score\n",
    "        naive_best_model = model\n",
    "#         multi_best_c = model.C_\n",
    "        naive_best_l = l\n",
    "        naive_best_train_df = nb_df.copy()\n",
    "\n",
    "print(f'Best l is {naive_best_l}')\n",
    "# print(f'Best Cs are {multi_best_c}')\n",
    "print(naive_best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5be15b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "#Test Data\n",
    "rows = []\n",
    "for df, path in zip(testing_dfs, testing_paths):\n",
    "    size = math.ceil(len(df) / naive_best_l)\n",
    "    label = path.split('/')[2]\n",
    "    label = labels[label]\n",
    "    row = []\n",
    "    column_names = []\n",
    "    for val in column_nums:\n",
    "        start = 0\n",
    "        part = 1\n",
    "        current = np.reshape(df.iloc[:,val-1].astype(float).values, (-1,1))\n",
    "        while start < len(df):\n",
    "            row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).mean())\n",
    "            column_names.append(f'Mean_{val}_{part}')\n",
    "            row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).quantile(0.25))\n",
    "            column_names.append(f'Q1_{val}_{part}')\n",
    "            row.append(df[df.columns[val-1]].iloc[start:start+size].astype(float).quantile(0.75))\n",
    "            column_names.append(f'Q3_{val}_{part}')\n",
    "            start = start + size\n",
    "            part += 1\n",
    "    row.append(label)\n",
    "    rows.append(row[:])\n",
    "\n",
    "column_names.append('Label')\n",
    "naive_test_df = pd.DataFrame(rows, columns = column_names)\n",
    "naive_test_df.shape\n",
    "\n",
    "X_test_df_naive = naive_test_df.iloc[:,:-1]\n",
    "y_test_df_naive = naive_test_df.iloc[:, -1]\n",
    "preds = naive_best_model.predict(X_test_df_naive)\n",
    "score = naive_best_model.score(X_test_df_naive, y_test_df_naive)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1830be8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[2 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0]\n",
      " [0 0 3 0 0 0 0]\n",
      " [0 0 0 3 0 0 0]\n",
      " [0 0 0 0 2 1 0]\n",
      " [0 0 0 0 0 3 0]\n",
      " [0 0 0 0 0 0 3]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAANiUlEQVR4nO3dcYjf9X3H8edrOYWVdirNtbgkmmzEtvlDN3u1MtZpVzYT90coyFBLZdKSykzpn8pg7R/+syIDKcaGIEH6T/PHKm06rpXBaC04t5yg0SjKLVJzS8GzFQX7h0bf++N+Hb/9vNzve+f37nKfez7g4L7f7+fu3h8Snn795u5+qSokSRvf7633AJKkfhh0SWqEQZekRhh0SWqEQZekRkys1xfeunVr7dy5c72+vCRtSE899dRrVTW52LV1C/rOnTuZmZlZry8vSRtSkl+e75qPXCSpEQZdkhph0CWpEQZdkhph0CWpEWODnuRokleTPHee60nynSSzSU4mubb/MSVJ43S5Q38E2LvE9X3A7sHbAeC7H3wsSdJyjf0+9Kp6PMnOJZbsB75XC7+H98kklya5vKp+1deQw6YP3s/lE1euxqeWpDXx5juvc8Ohr/X+eft4hr4NODN0PDc49z5JDiSZSTIzPz+/oi92+cSVXHLRZSv6WElqWR8/KZpFzi36qhlVdQQ4AjA1NbXiV9Z4453X+dMH/nalHy5JTerjDn0O2DF0vB0428PnlSQtQx9BPw7cMfhul+uBN1br+bkk6fzGPnJJ8n3gRmBrkjngW8BFAFV1GJgGbgZmgd8Cd67WsJKk8+vyXS63jblewN29TSRJWhF/UlSSGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGtEp6En2JnkxyWySexe5fkmSHyd5JsmpJHf2P6okaSljg55kC3AI2AfsAW5Lsmdk2d3A81V1DXAj8M9JLu55VknSErrcoV8HzFbV6ap6GzgG7B9ZU8BHkgT4MPAb4Fyvk0qSltQl6NuAM0PHc4Nzwx4EPgWcBZ4FvlFV741+oiQHkswkmZmfn1/hyJKkxXQJehY5VyPHNwFPA38I/AnwYJI/eN8HVR2pqqmqmpqcnFzmqJKkpXQJ+hywY+h4Owt34sPuBB6tBbPAy8An+xlRktRFl6CfAHYn2TX4h85bgeMja14BvgCQ5OPAJ4DTfQ4qSVraxLgFVXUuyUHgMWALcLSqTiW5a3D9MHAf8EiSZ1l4RHNPVb22inNLkkaMDTpAVU0D0yPnDg+9fxb4635HkyQthz8pKkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1IhOQU+yN8mLSWaT3HueNTcmeTrJqSQ/73dMSdI4E+MWJNkCHAL+CpgDTiQ5XlXPD625FHgI2FtVryT52CrNK0k6jy536NcBs1V1uqreBo4B+0fW3A48WlWvAFTVq/2OKUkap0vQtwFnho7nBueGXQVcluRnSZ5KcsdinyjJgSQzSWbm5+dXNrEkaVFdgp5FztXI8QTwaeBvgJuAf0xy1fs+qOpIVU1V1dTk5OSyh5Uknd/YZ+gs3JHvGDreDpxdZM1rVfUW8FaSx4FrgJd6mVKSNFaXO/QTwO4ku5JcDNwKHB9Z8yPgc0kmknwI+CzwQr+jSpKWMvYOvarOJTkIPAZsAY5W1akkdw2uH66qF5L8FDgJvAc8XFXPrebgkqT/r8sjF6pqGpgeOXd45Ph+4P7+RpMkLYc/KSpJjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjTDoktQIgy5JjegU9CR7k7yYZDbJvUus+0ySd5Pc0t+IkqQuxgY9yRbgELAP2APclmTPedZ9G3is7yElSeN1uUO/DpitqtNV9TZwDNi/yLqvAz8AXu1xPklSR12Cvg04M3Q8Nzj3f5JsA74IHF7qEyU5kGQmycz8/PxyZ5UkLaFL0LPIuRo5fgC4p6reXeoTVdWRqpqqqqnJycmOI0qSupjosGYO2DF0vB04O7JmCjiWBGArcHOSc1X1wz6GlCSN1yXoJ4DdSXYB/wPcCtw+vKCqdv3u/SSPAP9qzCVpbY0NelWdS3KQhe9e2QIcrapTSe4aXF/yubkkaW10uUOnqqaB6ZFzi4a8qv7ug48lSVouf1JUkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEQZdkhph0CWpEZ2CnmRvkheTzCa5d5HrX0pycvD2RJJr+h9VkrSUsUFPsgU4BOwD9gC3Jdkzsuxl4Iaquhq4DzjS96CSpKV1uUO/DpitqtNV9TZwDNg/vKCqnqiq1weHTwLb+x1TkjROl6BvA84MHc8Nzp3PV4CfLHYhyYEkM0lm5ufnu08pSRqrS9CzyLladGHyeRaCfs9i16vqSFVNVdXU5ORk9yklSWNNdFgzB+wYOt4OnB1dlORq4GFgX1X9up/xJElddblDPwHsTrIrycXArcDx4QVJrgAeBb5cVS/1P6YkaZyxd+hVdS7JQeAxYAtwtKpOJblrcP0w8E3go8BDSQDOVdXU6o0tSRrV5ZELVTUNTI+cOzz0/leBr/Y7miRpOfxJUUlqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqRKegJ9mb5MUks0nuXeR6knxncP1kkmv7H1WStJSxQU+yBTgE7AP2ALcl2TOybB+we/B2APhuz3NKksbocod+HTBbVaer6m3gGLB/ZM1+4Hu14Eng0iSX9zyrJGkJXYK+DTgzdDw3OLfcNSQ5kGQmycz8/PxyZwXgzXde5813Xl/Rx0pSyyY6rMki52oFa6iqI8ARgKmpqfdd7+KGQ19byYdJUvO63KHPATuGjrcDZ1ewRpK0iroE/QSwO8muJBcDtwLHR9YcB+4YfLfL9cAbVfWrnmeVJC1h7COXqjqX5CDwGLAFOFpVp5LcNbh+GJgGbgZmgd8Cd67eyJKkxXR5hk5VTbMQ7eFzh4feL+DufkeTJC2HPykqSY0w6JLUCIMuSY0w6JLUiCz8e+Y6fOFkHvjlCj98K/Baj+NsBO55c3DPm8MH2fOVVTW52IV1C/oHkWSmqqbWe4615J43B/e8OazWnn3kIkmNMOiS1IiNGvQj6z3AOnDPm4N73hxWZc8b8hm6JOn9NuoduiRphEGXpEZc0EHfjC9O3WHPXxrs9WSSJ5Jcsx5z9mncnofWfSbJu0luWcv5VkOXPSe5McnTSU4l+flaz9i3Dn+3L0ny4yTPDPa8oX9ra5KjSV5N8tx5rvffr6q6IN9Y+FW9/w38EXAx8AywZ2TNzcBPWHjFpOuB/1zvuddgz38GXDZ4f99m2PPQun9n4bd+3rLec6/Bn/OlwPPAFYPjj6333Guw538Avj14fxL4DXDxes/+Afb8F8C1wHPnud57vy7kO/TN+OLUY/dcVU9U1e9eVPVJFl4daiPr8ucM8HXgB8CrazncKumy59uBR6vqFYCq2uj77rLnAj6SJMCHWQj6ubUdsz9V9TgLezif3vt1IQe9txen3kCWu5+vsPBf+I1s7J6TbAO+CBymDV3+nK8CLkvysyRPJbljzaZbHV32/CDwKRZevvJZ4BtV9d7ajLcueu9Xpxe4WCe9vTj1BtJ5P0k+z0LQ/3xVJ1p9Xfb8AHBPVb27cPO24XXZ8wTwaeALwO8D/5Hkyap6abWHWyVd9nwT8DTwl8AfA/+W5BdV9eYqz7Zeeu/XhRz0zfji1J32k+Rq4GFgX1X9eo1mWy1d9jwFHBvEfCtwc5JzVfXDNZmwf13/br9WVW8BbyV5HLgG2KhB77LnO4F/qoUHzLNJXgY+CfzX2oy45nrv14X8yGUzvjj12D0nuQJ4FPjyBr5bGzZ2z1W1q6p2VtVO4F+Av9/AMYduf7d/BHwuyUSSDwGfBV5Y4zn71GXPr7DwfyQk+TjwCeD0mk65tnrv1wV7h16b8MWpO+75m8BHgYcGd6znagP/prqOe25Klz1X1QtJfgqcBN4DHq6qRb/9bSPo+Od8H/BIkmdZeBxxT1Vt2F+rm+T7wI3A1iRzwLeAi2D1+uWP/ktSIy7kRy6SpGUw6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY34X6cFlGebUDdbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(y_test_df_naive, preds)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "pred_proba = naive_best_model.predict_proba(X_test_df_naive).T\n",
    "for i, probs in enumerate(pred_proba):\n",
    "#     print(probs)\n",
    "    current_y = (preds == i).astype(int)\n",
    "#     print(current_y)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(current_y, probs, drop_intermediate=False)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64efb0c2",
   "metadata": {},
   "source": [
    "### iii. Which method is better for multi-class classification in this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab01b366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0b0a5ce",
   "metadata": {},
   "source": [
    "# 3. ISLR, 4.8.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f9ee00",
   "metadata": {},
   "source": [
    "# 4. ISLR 4.8.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ba8a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67e128d9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
