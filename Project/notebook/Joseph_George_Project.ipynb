{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a9bbd7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a9bbd7e",
    "outputId": "a8bf92c0-dd51-4672-ac5a-309d4bdc3576"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting tensorflow_addons\n",
      "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 33.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (2.7.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
      "Installing collected packages: tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8sT5W1YMuNeW",
   "metadata": {
    "id": "8sT5W1YMuNeW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, GlobalMaxPooling2D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.applications import EfficientNetB0, vgg16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "_n_pghiuu-Q-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_n_pghiuu-Q-",
    "outputId": "cdc55037-370f-45b0-a88a-78a9b9437834"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24844866",
   "metadata": {
    "id": "24844866"
   },
   "source": [
    "# 1. Transfer Learning for Image Classification1\n",
    "# It is highly recommended that you complete this project using Keras2 and Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4339b8d0",
   "metadata": {
    "id": "4339b8d0"
   },
   "source": [
    "## (a) In this problem, we are trying to build a classifier that distinguishes images of 20 bird species. You are provided with text data in twenty folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adeba1d",
   "metadata": {
    "id": "5adeba1d"
   },
   "source": [
    "> Data has been downloaded from the Folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b91275f",
   "metadata": {
    "id": "8b91275f"
   },
   "source": [
    "## (b) Data Exploration and Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b5221e",
   "metadata": {
    "id": "55b5221e"
   },
   "source": [
    "### i. Images in each class are given in separate folders. The file Classes.xlsx provides the classes assigned to the bird species images in each folder. Therefore, you encode your classes using one-hot encoding and Classes.xlsx.\n",
    "### ii. Randomly select ⌈0.7ni⌉ images from each folder as your training set, ⌈0.15ni⌉ as validation set, and the rest as your test set, where ni is the number of images in folder i and ⌈x⌉ is the ceiling of x.\n",
    "### iii. In order for all the images to have the same size, zero-pad or resize the images in your dataset. This can be done using various tools, including OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffd38abb",
   "metadata": {
    "id": "ffd38abb"
   },
   "outputs": [],
   "source": [
    "classes = pd.read_excel(\"/content/drive/MyDrive/data/Classes.xlsx\", names=['folder', 'class'])\n",
    "classes['folder'] = classes['folder'].str.split('.').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9918553c",
   "metadata": {
    "id": "9918553c"
   },
   "outputs": [],
   "source": [
    "memcache = classes.set_index('folder').T.to_dict('list')\n",
    "memcache = dict((k.lower(), v) for k, v in memcache.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad39085f",
   "metadata": {
    "id": "ad39085f"
   },
   "outputs": [],
   "source": [
    "dirpath = '/content/drive/MyDrive/data/images'\n",
    "for foldername in os.listdir(dirpath):\n",
    "    if foldername == \".DS_Store\": continue\n",
    "    temp = []\n",
    "    for filename in os.listdir(os.path.join(dirpath, foldername)):\n",
    "        temp.append(os.path.join(dirpath,foldername,filename))\n",
    "    memcache[foldername.split('.')[1].lower()].append(temp)\n",
    "    \n",
    "split_cache = {}\n",
    "train_images, train_labels, validation_images, validation_labels, test_images, test_labels = [], [], [], [], [], []\n",
    "for key, values in memcache.items():\n",
    "    length = len(values[1])\n",
    "    indices = set([i for i in range(length)])\n",
    "    train_indices = random.sample(list(indices), math.ceil(0.7*len(indices)))\n",
    "    indices = indices - set(train_indices)\n",
    "    validation_indices = random.sample(list(indices), math.ceil(0.15*len(indices)))\n",
    "    indices = indices - set(validation_indices)\n",
    "    split_cache[key] = (train_indices, validation_indices, indices)\n",
    "    \n",
    "    images = np.array(values[1])\n",
    "    train_images.extend(images[train_indices])\n",
    "    train_labels.extend([[values[0]] for _ in train_indices])\n",
    "    validation_images.extend(images[validation_indices])\n",
    "    validation_labels.extend([[values[0]] for _ in validation_indices])\n",
    "    test_images.extend(images[list(indices)])\n",
    "    test_labels.extend([[values[0]] for _ in indices])\n",
    "\n",
    "train_df = pd.DataFrame({'Images': train_images, 'Class': train_labels})\n",
    "validation_df = pd.DataFrame({'Images': validation_images, 'Class': validation_labels})\n",
    "test_df = pd.DataFrame({'Images': test_images, 'Class': test_labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d07e8a",
   "metadata": {
    "id": "c1d07e8a"
   },
   "source": [
    "## (c) Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613d14e8",
   "metadata": {
    "id": "613d14e8"
   },
   "source": [
    "### i. When dealing with classification of relatively small image datasets, deep net- works may not perform very well because of not having enough data to train them. In such cases, one usually uses transfer learning, which uses deep learning models that are trained on very large datasets such as ImageNet as feature extractors. The idea is that such deep networks have learned to extract meaningful features from an image using their layers, and those fea- tures can be used in learning other tasks. In order to do that, usually the last layer or the last few layers of the pre-trained network are removed, and the response of the layer before the removed layers to the images in the new dataset is used as a feature vector to train one more multiple replacement lay- ers. The dataset in this task has only around 50-60 images per class. Given that we have 20 classes, training a deep network with such a small dataset may not yield desirable results. In this project, you will use pre-trained mod- els EfficientNetB0 and VGG16. For both pre-trained networks, you will only train the last fully connected layer, and will freeze all layers before them (i.e. we do not change their parameters during training) and use the outputs of the penultimate layer in the original pre-trained model as the features extracted from each image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a700dec",
   "metadata": {
    "id": "5a700dec"
   },
   "source": [
    "### ii. To perform empirical regularization, crop, randomly zoo, rotate, flip, contrast, and translate images in your training set for image augmentation. You can use various tools to do this, including OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621bc227",
   "metadata": {
    "id": "621bc227"
   },
   "source": [
    "### iii. Use ReLU activation functions in the last layer and a softmax layer, along with batch normalization 4 and a dropout rate of 20% as well as ADAM optimizer. Use multinomial cross entropy loss. You can try any batch size, but a batch size of 5 seems reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9643db9",
   "metadata": {
    "id": "e9643db9"
   },
   "source": [
    "### iv. Train the networks (EfficientNetB0 and VGG16) for at least 50 epochs (preferably 100 epochs) and perform early stopping using the validation set. Keep the network parameters that have the lowest validation error. Plot the training and validation errors vs. epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86e0a240",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "86e0a240",
    "outputId": "156594d0-958b-45e5-fbd4-a5abaa0e62b1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-629c653b-ecd6-4544-bd06-0f5f0fd25f64\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Images</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/content/drive/MyDrive/data/images/005.Crested...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/content/drive/MyDrive/data/images/005.Crested...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/content/drive/MyDrive/data/images/005.Crested...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/content/drive/MyDrive/data/images/005.Crested...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/content/drive/MyDrive/data/images/005.Crested...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>/content/drive/MyDrive/data/images/168.Kentuck...</td>\n",
       "      <td>[19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>/content/drive/MyDrive/data/images/168.Kentuck...</td>\n",
       "      <td>[19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>/content/drive/MyDrive/data/images/168.Kentuck...</td>\n",
       "      <td>[19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>/content/drive/MyDrive/data/images/168.Kentuck...</td>\n",
       "      <td>[19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>/content/drive/MyDrive/data/images/168.Kentuck...</td>\n",
       "      <td>[19]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>827 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-629c653b-ecd6-4544-bd06-0f5f0fd25f64')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-629c653b-ecd6-4544-bd06-0f5f0fd25f64 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-629c653b-ecd6-4544-bd06-0f5f0fd25f64');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                Images Class\n",
       "0    /content/drive/MyDrive/data/images/005.Crested...   [0]\n",
       "1    /content/drive/MyDrive/data/images/005.Crested...   [0]\n",
       "2    /content/drive/MyDrive/data/images/005.Crested...   [0]\n",
       "3    /content/drive/MyDrive/data/images/005.Crested...   [0]\n",
       "4    /content/drive/MyDrive/data/images/005.Crested...   [0]\n",
       "..                                                 ...   ...\n",
       "822  /content/drive/MyDrive/data/images/168.Kentuck...  [19]\n",
       "823  /content/drive/MyDrive/data/images/168.Kentuck...  [19]\n",
       "824  /content/drive/MyDrive/data/images/168.Kentuck...  [19]\n",
       "825  /content/drive/MyDrive/data/images/168.Kentuck...  [19]\n",
       "826  /content/drive/MyDrive/data/images/168.Kentuck...  [19]\n",
       "\n",
       "[827 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2f96096",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2f96096",
    "outputId": "e36b12c7-361a-411a-e75d-fa0682ea0d33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 827 non-validated image filenames belonging to 20 classes.\n",
      "Found 59 non-validated image filenames belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "validate_filenames=False,\n",
    "dataframe = train_df, \n",
    "directory = '',\n",
    "x_col = 'Images',\n",
    "y_col = 'Class',\n",
    "class_mode = 'categorical',\n",
    "batch_size = 5,\n",
    "target_size=(224,224))\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "validation_generator = test_datagen.flow_from_dataframe(\n",
    "validate_filenames=False,\n",
    "dataframe = validation_df,\n",
    "directory = '',\n",
    "x_col = 'Images',\n",
    "y_col = 'Class',\n",
    "class_mode = 'categorical',\n",
    "batch_size = 5,\n",
    "target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89575990",
   "metadata": {
    "id": "89575990"
   },
   "outputs": [],
   "source": [
    "# Utility function for plotting of the model results\n",
    "def visualize_results(history):\n",
    "    # Plot the accuracy and loss curves\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    " \n",
    "    epochs = range(len(acc))\n",
    " \n",
    "    plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    " \n",
    "    plt.figure()\n",
    " \n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    " \n",
    "    plt.show()\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    lr = 1e-4\n",
    "    return lr * pow(0.99,epoch)\n",
    "\n",
    "\n",
    "lr = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dd6f54c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0dd6f54c",
    "outputId": "5c885432-3dcf-4a13-9804-979786703a1a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16705208/16705208 [==============================] - 2s 0us/step\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fc986027280> False\n",
      "<keras.layers.preprocessing.image_preprocessing.Rescaling object at 0x7fc986027b80> False\n",
      "<keras.layers.preprocessing.normalization.Normalization object at 0x7fc986027df0> False\n",
      "<keras.layers.core.tf_op_layer.TFOpLambda object at 0x7fc9857ad4f0> False\n",
      "<keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x7fc9857adf70> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9fa762fa0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc985765c70> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc986027ee0> False\n",
      "<keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D object at 0x7fc9857ada90> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9703ff9d0> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc97043ca00> False\n",
      "<keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7fc97043c1c0> False\n",
      "<keras.layers.reshaping.reshape.Reshape object at 0x7fc97043cf40> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc97043e8e0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc97043ebb0> False\n",
      "<keras.layers.merging.multiply.Multiply object at 0x7fc97043e580> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9703d3fd0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9703db040> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc985765dc0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9703e3070> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc9703e9250> False\n",
      "<keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x7fc9703f87f0> False\n",
      "<keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D object at 0x7fc9703db190> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9703fd340> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc9703856d0> False\n",
      "<keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7fc970385bb0> False\n",
      "<keras.layers.reshaping.reshape.Reshape object at 0x7fc9703fd1f0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc97038cbb0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc970394eb0> False\n",
      "<keras.layers.merging.multiply.Multiply object at 0x7fc970394df0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc97039cb50> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9703a2f40> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9703a2df0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9703a23d0> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc9703b63a0> False\n",
      "<keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D object at 0x7fc9703b6f40> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9703bd790> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc970341160> False\n",
      "<keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7fc97039ceb0> False\n",
      "<keras.layers.reshaping.reshape.Reshape object at 0x7fc9703bdf10> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc97038c940> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9703f2280> False\n",
      "<keras.layers.merging.multiply.Multiply object at 0x7fc9703ffc10> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc97043e190> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc970349a60> False\n",
      "<keras.layers.regularization.dropout.Dropout object at 0x7fc970349c40> False\n",
      "<keras.layers.merging.add.Add object at 0x7fc97043edc0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9703e9220> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc97034f5e0> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc98579f130> False\n",
      "<keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x7fc98579fb50> False\n",
      "<keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D object at 0x7fc970352670> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc97035ec70> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc970366640> False\n",
      "<keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7fc9703667c0> False\n",
      "<keras.layers.reshaping.reshape.Reshape object at 0x7fc97036b400> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9703722e0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9703725b0> False\n",
      "<keras.layers.merging.multiply.Multiply object at 0x7fc9703729d0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9703009a0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc970300c40> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc970307430> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc970316730> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc970316610> False\n",
      "<keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D object at 0x7fc9703072e0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc970320a30> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc970320a00> False\n",
      "<keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7fc970329460> False\n",
      "<keras.layers.reshaping.reshape.Reshape object at 0x7fc970329d00> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc97032fe80> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc97032f910> False\n",
      "<keras.layers.merging.multiply.Multiply object at 0x7fc97030d3a0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9702c0fd0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9702c0e50> False\n",
      "<keras.layers.regularization.dropout.Dropout object at 0x7fc9702c9b80> False\n",
      "<keras.layers.merging.add.Add object at 0x7fc9702d5790> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9702d5ee0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9702d5dc0> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc9702c9310> False\n",
      "<keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x7fc97031ca00> False\n",
      "<keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D object at 0x7fc970320bb0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc970366730> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc97043ebe0> False\n",
      "<keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7fc9703668e0> False\n",
      "<keras.layers.reshaping.reshape.Reshape object at 0x7fc97036b5b0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9702e1040> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9702e1310> False\n",
      "<keras.layers.merging.multiply.Multiply object at 0x7fc9702e1f10> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9702e3f70> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9702ec640> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9702e3070> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9702ec670> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc9702f55e0> False\n",
      "<keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D object at 0x7fc9702f52b0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc970280bb0> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc970286580> False\n",
      "<keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7fc9702863d0> False\n",
      "<keras.layers.reshaping.reshape.Reshape object at 0x7fc970280910> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc970294640> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc970294910> False\n",
      "<keras.layers.merging.multiply.Multiply object at 0x7fc970294cd0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9702a4580> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9702a8970> False\n",
      "<keras.layers.regularization.dropout.Dropout object at 0x7fc9702a8d00> False\n",
      "<keras.layers.merging.add.Add object at 0x7fc9702a4be0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9702b1cd0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9702b3df0> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc9702b3e80> False\n",
      "<keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D object at 0x7fc9702b1e50> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc970244eb0> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc970244e80> False\n",
      "<keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7fc97024d940> False\n",
      "<keras.layers.reshaping.reshape.Reshape object at 0x7fc9702539a0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc97024dac0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc970253e20> False\n",
      "<keras.layers.merging.multiply.Multiply object at 0x7fc970268d60> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc97025fdc0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc97025ffd0> False\n",
      "<keras.layers.regularization.dropout.Dropout object at 0x7fc9702f5880> False\n",
      "<keras.layers.merging.add.Add object at 0x7fc9702804c0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9702d5cd0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc970286970> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc970276520> False\n",
      "<keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D object at 0x7fc9702767c0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc970277cd0> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc97027a6a0> False\n",
      "<keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7fc97027a520> False\n",
      "<keras.layers.reshaping.reshape.Reshape object at 0x7fc970277d60> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc97027e790> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc97027ea60> False\n",
      "<keras.layers.merging.multiply.Multiply object at 0x7fc97027edc0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc970214700> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc97021daf0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc97021de80> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc97021d670> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc970229bb0> False\n",
      "<keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D object at 0x7fc9702149a0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc970230fd0> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc97023a340> False\n",
      "<keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7fc97023a4f0> False\n",
      "<keras.layers.reshaping.reshape.Reshape object at 0x7fc97023e130> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9701c6d90> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9701ceca0> False\n",
      "<keras.layers.merging.multiply.Multiply object at 0x7fc9701cee50> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9701d8d00> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9701dce20> False\n",
      "<keras.layers.regularization.dropout.Dropout object at 0x7fc9701d8ca0> False\n",
      "<keras.layers.merging.add.Add object at 0x7fc9701e64f0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9701ea490> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9701ea3a0> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc9701e67f0> False\n",
      "<keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D object at 0x7fc9701f3790> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9701f87f0> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc9701f8d90> False\n",
      "<keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7fc9701fdf40> False\n",
      "<keras.layers.reshaping.reshape.Reshape object at 0x7fc97018bbe0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc97018bfd0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc97018b760> False\n",
      "<keras.layers.merging.multiply.Multiply object at 0x7fc9701c6670> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9701ea730> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc970214a90> False\n",
      "<keras.layers.regularization.dropout.Dropout object at 0x7fc98578ad60> False\n",
      "<keras.layers.merging.add.Add object at 0x7fc97028ca60> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc970286a60> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9701fd0a0> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc97034f7f0> False\n",
      "<keras.layers.reshaping.zero_padding2d.ZeroPadding2D object at 0x7fc97027ab50> False\n",
      "<keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D object at 0x7fc97032fa90> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9702a8a30> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc97019e610> False\n",
      "<keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7fc9701a6430> False\n",
      "<keras.layers.reshaping.reshape.Reshape object at 0x7fc97019b730> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9701881c0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc970214d90> False\n",
      "<keras.layers.merging.multiply.Multiply object at 0x7fc97021dbe0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc97024d790> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9701bdac0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9701e62e0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc970163d00> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc9701632b0> False\n",
      "<keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D object at 0x7fc970144ca0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9701a69a0> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc970159ee0> False\n",
      "<keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7fc970175a00> False\n",
      "<keras.layers.reshaping.reshape.Reshape object at 0x7fc9701697f0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9700ff370> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc970175d90> False\n",
      "<keras.layers.merging.multiply.Multiply object at 0x7fc9701127f0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc970144610> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc970112640> False\n",
      "<keras.layers.regularization.dropout.Dropout object at 0x7fc9700ffc70> False\n",
      "<keras.layers.merging.add.Add object at 0x7fc97028cf40> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc98578ae80> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc970103be0> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc970132070> False\n",
      "<keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D object at 0x7fc970132910> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9701328b0> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc97012abb0> False\n",
      "<keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7fc970159d60> False\n",
      "<keras.layers.reshaping.reshape.Reshape object at 0x7fc970132760> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc970144a60> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc97012a2e0> False\n",
      "<keras.layers.merging.multiply.Multiply object at 0x7fc9701444f0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9701fd850> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9701ac160> False\n",
      "<keras.layers.regularization.dropout.Dropout object at 0x7fc970103c70> False\n",
      "<keras.layers.merging.add.Add object at 0x7fc97013a9d0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc970118ca0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc970229eb0> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc9701fd910> False\n",
      "<keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D object at 0x7fc970229dc0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9701634c0> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc970229df0> False\n",
      "<keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7fc9700d0f70> False\n",
      "<keras.layers.reshaping.reshape.Reshape object at 0x7fc970230580> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9700c8df0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc97014f040> False\n",
      "<keras.layers.merging.multiply.Multiply object at 0x7fc9700d01f0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc970196fa0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9700e1640> False\n",
      "<keras.layers.regularization.dropout.Dropout object at 0x7fc9700e1340> False\n",
      "<keras.layers.merging.add.Add object at 0x7fc9700f5970> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc970196af0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9700fc8b0> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc9700e7100> False\n",
      "<keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D object at 0x7fc9700e7cd0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9700d0550> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc9700899d0> False\n",
      "<keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7fc970089ee0> False\n",
      "<keras.layers.reshaping.reshape.Reshape object at 0x7fc9700fc820> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9700d0400> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9700fce80> False\n",
      "<keras.layers.merging.multiply.Multiply object at 0x7fc970099280> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9700e73d0> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc970089160> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc9857adb20> False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fc9700e7460> False\n",
      "<keras.layers.core.activation.Activation object at 0x7fc9700ba700> True\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb0 (Functional)  (None, 7, 7, 1280)       4049571   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 62720)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 362)               22705002  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 362)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 362)              1448      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                7260      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,763,281\n",
      "Trainable params: 22,712,986\n",
      "Non-trainable params: 4,050,295\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "eff_conv = EfficientNetB0(weights = 'imagenet', include_top = False, input_shape = (224,224,3))\n",
    "for layer in eff_conv.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "for layer in eff_conv.layers:\n",
    "    print(layer, layer.trainable)\n",
    "filepath = 'efficient_b0_best_model.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, \n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30)\n",
    "model = Sequential()\n",
    "model.add(eff_conv)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(362, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(20, activation='softmax'))\n",
    "opt = Adam()\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tfa.metrics.F1Score(num_classes=20)])\n",
    " \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0032a6c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0032a6c8",
    "outputId": "26a559d0-c150-4fcb-e76c-8cc7e2cefd07",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 2.4564 - accuracy: 0.3313 - precision: 0.5740 - recall: 0.1548 - f1_score: 0.3292\n",
      "Epoch 1: val_loss improved from inf to 1.22059, saving model to efficient_b0_best_model.hdf5\n",
      "165/165 [==============================] - 88s 434ms/step - loss: 2.4564 - accuracy: 0.3313 - precision: 0.5740 - recall: 0.1548 - f1_score: 0.3292 - val_loss: 1.2206 - val_accuracy: 0.6610 - val_precision: 0.7708 - val_recall: 0.6271 - val_f1_score: 0.6088 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 1.5703 - accuracy: 0.5231 - precision: 0.7802 - recall: 0.3540 - f1_score: 0.5197\n",
      "Epoch 2: val_loss improved from 1.22059 to 0.60441, saving model to efficient_b0_best_model.hdf5\n",
      "165/165 [==============================] - 22s 119ms/step - loss: 1.5729 - accuracy: 0.5236 - precision: 0.7819 - recall: 0.3555 - f1_score: 0.5200 - val_loss: 0.6044 - val_accuracy: 0.8305 - val_precision: 0.9333 - val_recall: 0.7119 - val_f1_score: 0.8343 - lr: 9.9000e-05\n",
      "Epoch 3/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 1.1194 - accuracy: 0.6740 - precision: 0.8518 - recall: 0.4964 - f1_score: 0.6708\n",
      "Epoch 3: val_loss improved from 0.60441 to 0.54232, saving model to efficient_b0_best_model.hdf5\n",
      "165/165 [==============================] - 22s 124ms/step - loss: 1.1195 - accuracy: 0.6747 - precision: 0.8524 - recall: 0.4958 - f1_score: 0.6721 - val_loss: 0.5423 - val_accuracy: 0.8475 - val_precision: 0.9200 - val_recall: 0.7797 - val_f1_score: 0.8444 - lr: 9.8010e-05\n",
      "Epoch 4/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 1.0314 - accuracy: 0.6953 - precision: 0.8687 - recall: 0.5441 - f1_score: 0.6918\n",
      "Epoch 4: val_loss improved from 0.54232 to 0.47491, saving model to efficient_b0_best_model.hdf5\n",
      "165/165 [==============================] - 20s 112ms/step - loss: 1.0314 - accuracy: 0.6953 - precision: 0.8687 - recall: 0.5441 - f1_score: 0.6918 - val_loss: 0.4749 - val_accuracy: 0.8305 - val_precision: 0.8704 - val_recall: 0.7966 - val_f1_score: 0.8161 - lr: 9.7030e-05\n",
      "Epoch 5/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.8816 - accuracy: 0.7445 - precision: 0.8987 - recall: 0.5827 - f1_score: 0.7432\n",
      "Epoch 5: val_loss improved from 0.47491 to 0.45839, saving model to efficient_b0_best_model.hdf5\n",
      "165/165 [==============================] - 20s 111ms/step - loss: 0.8787 - accuracy: 0.7461 - precision: 0.8994 - recall: 0.5840 - f1_score: 0.7448 - val_loss: 0.4584 - val_accuracy: 0.8305 - val_precision: 0.8889 - val_recall: 0.8136 - val_f1_score: 0.8256 - lr: 9.6060e-05\n",
      "Epoch 6/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.8144 - accuracy: 0.7749 - precision: 0.9141 - recall: 0.6472 - f1_score: 0.7740\n",
      "Epoch 6: val_loss improved from 0.45839 to 0.41238, saving model to efficient_b0_best_model.hdf5\n",
      "165/165 [==============================] - 24s 140ms/step - loss: 0.8130 - accuracy: 0.7751 - precision: 0.9131 - recall: 0.6481 - f1_score: 0.7744 - val_loss: 0.4124 - val_accuracy: 0.8475 - val_precision: 0.8889 - val_recall: 0.8136 - val_f1_score: 0.8356 - lr: 9.5099e-05\n",
      "Epoch 7/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.7314 - accuracy: 0.7981 - precision: 0.9082 - recall: 0.6699 - f1_score: 0.7976\n",
      "Epoch 7: val_loss did not improve from 0.41238\n",
      "165/165 [==============================] - 18s 104ms/step - loss: 0.7314 - accuracy: 0.7981 - precision: 0.9082 - recall: 0.6699 - f1_score: 0.7976 - val_loss: 0.4276 - val_accuracy: 0.8475 - val_precision: 0.8909 - val_recall: 0.8305 - val_f1_score: 0.8404 - lr: 9.4148e-05\n",
      "Epoch 8/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.7020 - accuracy: 0.7811 - precision: 0.8921 - recall: 0.6699 - f1_score: 0.7805\n",
      "Epoch 8: val_loss did not improve from 0.41238\n",
      "165/165 [==============================] - 20s 116ms/step - loss: 0.7020 - accuracy: 0.7811 - precision: 0.8921 - recall: 0.6699 - f1_score: 0.7805 - val_loss: 0.4789 - val_accuracy: 0.8305 - val_precision: 0.9038 - val_recall: 0.7966 - val_f1_score: 0.8282 - lr: 9.3207e-05\n",
      "Epoch 9/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.6966 - accuracy: 0.7798 - precision: 0.9124 - recall: 0.6715 - f1_score: 0.7785\n",
      "Epoch 9: val_loss improved from 0.41238 to 0.38866, saving model to efficient_b0_best_model.hdf5\n",
      "165/165 [==============================] - 22s 126ms/step - loss: 0.7010 - accuracy: 0.7775 - precision: 0.9097 - recall: 0.6699 - f1_score: 0.7763 - val_loss: 0.3887 - val_accuracy: 0.8983 - val_precision: 0.9091 - val_recall: 0.8475 - val_f1_score: 0.8986 - lr: 9.2274e-05\n",
      "Epoch 10/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.6707 - accuracy: 0.8114 - precision: 0.9220 - recall: 0.7146 - f1_score: 0.8122\n",
      "Epoch 10: val_loss did not improve from 0.38866\n",
      "165/165 [==============================] - 19s 108ms/step - loss: 0.6707 - accuracy: 0.8114 - precision: 0.9220 - recall: 0.7146 - f1_score: 0.8122 - val_loss: 0.4266 - val_accuracy: 0.8644 - val_precision: 0.9074 - val_recall: 0.8305 - val_f1_score: 0.8643 - lr: 9.1352e-05\n",
      "Epoch 11/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.5831 - accuracy: 0.8428 - precision: 0.9287 - recall: 0.7400 - f1_score: 0.8421\n",
      "Epoch 11: val_loss did not improve from 0.38866\n",
      "165/165 [==============================] - 18s 105ms/step - loss: 0.5831 - accuracy: 0.8428 - precision: 0.9287 - recall: 0.7400 - f1_score: 0.8421 - val_loss: 0.4028 - val_accuracy: 0.8644 - val_precision: 0.9216 - val_recall: 0.7966 - val_f1_score: 0.8456 - lr: 9.0438e-05\n",
      "Epoch 12/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.5866 - accuracy: 0.8174 - precision: 0.9191 - recall: 0.7279 - f1_score: 0.8175\n",
      "Epoch 12: val_loss did not improve from 0.38866\n",
      "165/165 [==============================] - 20s 114ms/step - loss: 0.5866 - accuracy: 0.8174 - precision: 0.9191 - recall: 0.7279 - f1_score: 0.8175 - val_loss: 0.4021 - val_accuracy: 0.8644 - val_precision: 0.8889 - val_recall: 0.8136 - val_f1_score: 0.8638 - lr: 8.9534e-05\n",
      "Epoch 13/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.5107 - accuracy: 0.8561 - precision: 0.9398 - recall: 0.7545 - f1_score: 0.8566\n",
      "Epoch 13: val_loss improved from 0.38866 to 0.38050, saving model to efficient_b0_best_model.hdf5\n",
      "165/165 [==============================] - 22s 125ms/step - loss: 0.5107 - accuracy: 0.8561 - precision: 0.9398 - recall: 0.7545 - f1_score: 0.8566 - val_loss: 0.3805 - val_accuracy: 0.8983 - val_precision: 0.9091 - val_recall: 0.8475 - val_f1_score: 0.8948 - lr: 8.8638e-05\n",
      "Epoch 14/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.5617 - accuracy: 0.8406 - precision: 0.9214 - recall: 0.7555 - f1_score: 0.8415\n",
      "Epoch 14: val_loss improved from 0.38050 to 0.35191, saving model to efficient_b0_best_model.hdf5\n",
      "165/165 [==============================] - 20s 113ms/step - loss: 0.5635 - accuracy: 0.8392 - precision: 0.9204 - recall: 0.7545 - f1_score: 0.8401 - val_loss: 0.3519 - val_accuracy: 0.8814 - val_precision: 0.9245 - val_recall: 0.8305 - val_f1_score: 0.8790 - lr: 8.7752e-05\n",
      "Epoch 15/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.5129 - accuracy: 0.8585 - precision: 0.9368 - recall: 0.7703 - f1_score: 0.8595\n",
      "Epoch 15: val_loss did not improve from 0.35191\n",
      "165/165 [==============================] - 20s 108ms/step - loss: 0.5129 - accuracy: 0.8585 - precision: 0.9368 - recall: 0.7703 - f1_score: 0.8595 - val_loss: 0.3544 - val_accuracy: 0.8983 - val_precision: 0.9107 - val_recall: 0.8644 - val_f1_score: 0.8961 - lr: 8.6875e-05\n",
      "Epoch 16/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.4868 - accuracy: 0.8589 - precision: 0.9296 - recall: 0.7871 - f1_score: 0.8589\n",
      "Epoch 16: val_loss improved from 0.35191 to 0.29822, saving model to efficient_b0_best_model.hdf5\n",
      "165/165 [==============================] - 22s 125ms/step - loss: 0.4847 - accuracy: 0.8597 - precision: 0.9301 - recall: 0.7884 - f1_score: 0.8596 - val_loss: 0.2982 - val_accuracy: 0.9153 - val_precision: 0.9259 - val_recall: 0.8475 - val_f1_score: 0.9119 - lr: 8.6006e-05\n",
      "Epoch 17/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.4692 - accuracy: 0.8625 - precision: 0.9449 - recall: 0.7932 - f1_score: 0.8629\n",
      "Epoch 17: val_loss did not improve from 0.29822\n",
      "165/165 [==============================] - 18s 104ms/step - loss: 0.4683 - accuracy: 0.8634 - precision: 0.9452 - recall: 0.7932 - f1_score: 0.8636 - val_loss: 0.3581 - val_accuracy: 0.8644 - val_precision: 0.8947 - val_recall: 0.8644 - val_f1_score: 0.8438 - lr: 8.5146e-05\n",
      "Epoch 18/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.4553 - accuracy: 0.8851 - precision: 0.9428 - recall: 0.7969 - f1_score: 0.8850\n",
      "Epoch 18: val_loss did not improve from 0.29822\n",
      "165/165 [==============================] - 19s 107ms/step - loss: 0.4553 - accuracy: 0.8851 - precision: 0.9428 - recall: 0.7969 - f1_score: 0.8850 - val_loss: 0.3089 - val_accuracy: 0.8983 - val_precision: 0.9608 - val_recall: 0.8305 - val_f1_score: 0.8931 - lr: 8.4294e-05\n",
      "Epoch 19/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.4859 - accuracy: 0.8601 - precision: 0.9525 - recall: 0.7798 - f1_score: 0.8606\n",
      "Epoch 19: val_loss did not improve from 0.29822\n",
      "165/165 [==============================] - 21s 118ms/step - loss: 0.4849 - accuracy: 0.8609 - precision: 0.9528 - recall: 0.7811 - f1_score: 0.8616 - val_loss: 0.3027 - val_accuracy: 0.9153 - val_precision: 0.9636 - val_recall: 0.8983 - val_f1_score: 0.9086 - lr: 8.3451e-05\n",
      "Epoch 20/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.4670 - accuracy: 0.8674 - precision: 0.9238 - recall: 0.7968 - f1_score: 0.8682\n",
      "Epoch 20: val_loss did not improve from 0.29822\n",
      "165/165 [==============================] - 21s 116ms/step - loss: 0.4647 - accuracy: 0.8682 - precision: 0.9244 - recall: 0.7981 - f1_score: 0.8691 - val_loss: 0.3058 - val_accuracy: 0.9322 - val_precision: 0.9630 - val_recall: 0.8814 - val_f1_score: 0.9293 - lr: 8.2617e-05\n",
      "Epoch 21/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3973 - accuracy: 0.8791 - precision: 0.9380 - recall: 0.8235 - f1_score: 0.8790\n",
      "Epoch 21: val_loss did not improve from 0.29822\n",
      "165/165 [==============================] - 20s 116ms/step - loss: 0.3973 - accuracy: 0.8791 - precision: 0.9380 - recall: 0.8235 - f1_score: 0.8790 - val_loss: 0.3162 - val_accuracy: 0.9322 - val_precision: 0.9474 - val_recall: 0.9153 - val_f1_score: 0.9314 - lr: 8.1791e-05\n",
      "Epoch 22/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.3770 - accuracy: 0.9027 - precision: 0.9480 - recall: 0.8431 - f1_score: 0.9036\n",
      "Epoch 22: val_loss did not improve from 0.29822\n",
      "165/165 [==============================] - 20s 111ms/step - loss: 0.3749 - accuracy: 0.9033 - precision: 0.9484 - recall: 0.8440 - f1_score: 0.9042 - val_loss: 0.3425 - val_accuracy: 0.8983 - val_precision: 0.9273 - val_recall: 0.8644 - val_f1_score: 0.8976 - lr: 8.0973e-05\n",
      "Epoch 23/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.4174 - accuracy: 0.8869 - precision: 0.9419 - recall: 0.8285 - f1_score: 0.8869\n",
      "Epoch 23: val_loss did not improve from 0.29822\n",
      "165/165 [==============================] - 18s 103ms/step - loss: 0.4168 - accuracy: 0.8863 - precision: 0.9422 - recall: 0.8283 - f1_score: 0.8860 - val_loss: 0.3298 - val_accuracy: 0.8983 - val_precision: 0.9123 - val_recall: 0.8814 - val_f1_score: 0.9007 - lr: 8.0163e-05\n",
      "Epoch 24/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3547 - accuracy: 0.9033 - precision: 0.9554 - recall: 0.8549 - f1_score: 0.9047\n",
      "Epoch 24: val_loss did not improve from 0.29822\n",
      "165/165 [==============================] - 19s 107ms/step - loss: 0.3547 - accuracy: 0.9033 - precision: 0.9554 - recall: 0.8549 - f1_score: 0.9047 - val_loss: 0.3629 - val_accuracy: 0.8983 - val_precision: 0.9444 - val_recall: 0.8644 - val_f1_score: 0.8990 - lr: 7.9361e-05\n",
      "Epoch 25/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3186 - accuracy: 0.9105 - precision: 0.9586 - recall: 0.8682 - f1_score: 0.9101\n",
      "Epoch 25: val_loss did not improve from 0.29822\n",
      "165/165 [==============================] - 19s 106ms/step - loss: 0.3186 - accuracy: 0.9105 - precision: 0.9586 - recall: 0.8682 - f1_score: 0.9101 - val_loss: 0.3366 - val_accuracy: 0.8983 - val_precision: 0.9091 - val_recall: 0.8475 - val_f1_score: 0.8971 - lr: 7.8568e-05\n",
      "Epoch 26/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.3694 - accuracy: 0.8881 - precision: 0.9519 - recall: 0.8418 - f1_score: 0.8878\n",
      "Epoch 26: val_loss improved from 0.29822 to 0.29287, saving model to efficient_b0_best_model.hdf5\n",
      "165/165 [==============================] - 23s 131ms/step - loss: 0.3704 - accuracy: 0.8875 - precision: 0.9521 - recall: 0.8416 - f1_score: 0.8872 - val_loss: 0.2929 - val_accuracy: 0.8983 - val_precision: 0.9107 - val_recall: 0.8644 - val_f1_score: 0.8948 - lr: 7.7782e-05\n",
      "Epoch 27/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3966 - accuracy: 0.9008 - precision: 0.9482 - recall: 0.8404 - f1_score: 0.9011\n",
      "Epoch 27: val_loss did not improve from 0.29287\n",
      "165/165 [==============================] - 19s 105ms/step - loss: 0.3966 - accuracy: 0.9008 - precision: 0.9482 - recall: 0.8404 - f1_score: 0.9011 - val_loss: 0.3190 - val_accuracy: 0.8983 - val_precision: 0.9259 - val_recall: 0.8475 - val_f1_score: 0.8971 - lr: 7.7004e-05\n",
      "Epoch 28/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.3488 - accuracy: 0.9002 - precision: 0.9448 - recall: 0.8540 - f1_score: 0.9004\n",
      "Epoch 28: val_loss improved from 0.29287 to 0.28856, saving model to efficient_b0_best_model.hdf5\n",
      "165/165 [==============================] - 22s 124ms/step - loss: 0.3542 - accuracy: 0.8984 - precision: 0.9450 - recall: 0.8513 - f1_score: 0.8984 - val_loss: 0.2886 - val_accuracy: 0.9153 - val_precision: 0.9273 - val_recall: 0.8644 - val_f1_score: 0.9152 - lr: 7.6234e-05\n",
      "Epoch 29/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3468 - accuracy: 0.9057 - precision: 0.9588 - recall: 0.8452 - f1_score: 0.9067\n",
      "Epoch 29: val_loss did not improve from 0.28856\n",
      "165/165 [==============================] - 21s 118ms/step - loss: 0.3468 - accuracy: 0.9057 - precision: 0.9588 - recall: 0.8452 - f1_score: 0.9067 - val_loss: 0.3209 - val_accuracy: 0.8983 - val_precision: 0.9123 - val_recall: 0.8814 - val_f1_score: 0.8948 - lr: 7.5472e-05\n",
      "Epoch 30/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3342 - accuracy: 0.9117 - precision: 0.9521 - recall: 0.8646 - f1_score: 0.9115\n",
      "Epoch 30: val_loss did not improve from 0.28856\n",
      "165/165 [==============================] - 19s 108ms/step - loss: 0.3342 - accuracy: 0.9117 - precision: 0.9521 - recall: 0.8646 - f1_score: 0.9115 - val_loss: 0.3535 - val_accuracy: 0.8814 - val_precision: 0.9286 - val_recall: 0.8814 - val_f1_score: 0.8800 - lr: 7.4717e-05\n",
      "Epoch 31/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.3178 - accuracy: 0.9136 - precision: 0.9609 - recall: 0.8674 - f1_score: 0.9141\n",
      "Epoch 31: val_loss did not improve from 0.28856\n",
      "165/165 [==============================] - 18s 103ms/step - loss: 0.3171 - accuracy: 0.9141 - precision: 0.9612 - recall: 0.8682 - f1_score: 0.9148 - val_loss: 0.3709 - val_accuracy: 0.8644 - val_precision: 0.9273 - val_recall: 0.8644 - val_f1_score: 0.8564 - lr: 7.3970e-05\n",
      "Epoch 32/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3193 - accuracy: 0.9021 - precision: 0.9469 - recall: 0.8622 - f1_score: 0.9027\n",
      "Epoch 32: val_loss did not improve from 0.28856\n",
      "165/165 [==============================] - 18s 103ms/step - loss: 0.3193 - accuracy: 0.9021 - precision: 0.9469 - recall: 0.8622 - f1_score: 0.9027 - val_loss: 0.3425 - val_accuracy: 0.8814 - val_precision: 0.9107 - val_recall: 0.8644 - val_f1_score: 0.8781 - lr: 7.3230e-05\n",
      "Epoch 33/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.2907 - accuracy: 0.9331 - precision: 0.9603 - recall: 0.8820 - f1_score: 0.9342\n",
      "Epoch 33: val_loss did not improve from 0.28856\n",
      "165/165 [==============================] - 22s 129ms/step - loss: 0.2925 - accuracy: 0.9323 - precision: 0.9604 - recall: 0.8803 - f1_score: 0.9335 - val_loss: 0.3105 - val_accuracy: 0.8983 - val_precision: 0.9298 - val_recall: 0.8983 - val_f1_score: 0.8989 - lr: 7.2498e-05\n",
      "Epoch 34/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.2508 - accuracy: 0.9323 - precision: 0.9723 - recall: 0.8924 - f1_score: 0.9318\n",
      "Epoch 34: val_loss did not improve from 0.28856\n",
      "165/165 [==============================] - 18s 103ms/step - loss: 0.2508 - accuracy: 0.9323 - precision: 0.9723 - recall: 0.8924 - f1_score: 0.9318 - val_loss: 0.3331 - val_accuracy: 0.8644 - val_precision: 0.9074 - val_recall: 0.8305 - val_f1_score: 0.8707 - lr: 7.1773e-05\n",
      "Epoch 35/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.2959 - accuracy: 0.9124 - precision: 0.9585 - recall: 0.8710 - f1_score: 0.9126\n",
      "Epoch 35: val_loss did not improve from 0.28856\n",
      "165/165 [==============================] - 21s 117ms/step - loss: 0.2969 - accuracy: 0.9117 - precision: 0.9587 - recall: 0.8706 - f1_score: 0.9122 - val_loss: 0.2987 - val_accuracy: 0.9153 - val_precision: 0.9138 - val_recall: 0.8983 - val_f1_score: 0.9132 - lr: 7.1055e-05\n",
      "Epoch 36/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.2651 - accuracy: 0.9319 - precision: 0.9724 - recall: 0.9015 - f1_score: 0.9325\n",
      "Epoch 36: val_loss improved from 0.28856 to 0.26888, saving model to efficient_b0_best_model.hdf5\n",
      "165/165 [==============================] - 22s 123ms/step - loss: 0.2650 - accuracy: 0.9311 - precision: 0.9726 - recall: 0.9008 - f1_score: 0.9316 - val_loss: 0.2689 - val_accuracy: 0.9322 - val_precision: 0.9322 - val_recall: 0.9322 - val_f1_score: 0.9286 - lr: 7.0345e-05\n",
      "Epoch 37/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.2835 - accuracy: 0.9319 - precision: 0.9580 - recall: 0.8881 - f1_score: 0.9322\n",
      "Epoch 37: val_loss improved from 0.26888 to 0.23692, saving model to efficient_b0_best_model.hdf5\n",
      "165/165 [==============================] - 19s 110ms/step - loss: 0.2859 - accuracy: 0.9311 - precision: 0.9582 - recall: 0.8875 - f1_score: 0.9312 - val_loss: 0.2369 - val_accuracy: 0.8983 - val_precision: 0.9455 - val_recall: 0.8814 - val_f1_score: 0.8986 - lr: 6.9641e-05\n",
      "Epoch 38/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.2890 - accuracy: 0.9141 - precision: 0.9486 - recall: 0.8706 - f1_score: 0.9147\n",
      "Epoch 38: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 19s 106ms/step - loss: 0.2890 - accuracy: 0.9141 - precision: 0.9486 - recall: 0.8706 - f1_score: 0.9147 - val_loss: 0.3188 - val_accuracy: 0.9153 - val_precision: 0.9153 - val_recall: 0.9153 - val_f1_score: 0.9152 - lr: 6.8945e-05\n",
      "Epoch 39/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.2988 - accuracy: 0.9117 - precision: 0.9538 - recall: 0.8730 - f1_score: 0.9115\n",
      "Epoch 39: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 19s 105ms/step - loss: 0.2988 - accuracy: 0.9117 - precision: 0.9538 - recall: 0.8730 - f1_score: 0.9115 - val_loss: 0.3250 - val_accuracy: 0.9153 - val_precision: 0.9091 - val_recall: 0.8475 - val_f1_score: 0.9152 - lr: 6.8255e-05\n",
      "Epoch 40/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.2613 - accuracy: 0.9297 - precision: 0.9620 - recall: 0.8897 - f1_score: 0.9304\n",
      "Epoch 40: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 21s 120ms/step - loss: 0.2625 - accuracy: 0.9299 - precision: 0.9620 - recall: 0.8888 - f1_score: 0.9305 - val_loss: 0.2616 - val_accuracy: 0.9153 - val_precision: 0.9286 - val_recall: 0.8814 - val_f1_score: 0.9132 - lr: 6.7573e-05\n",
      "Epoch 41/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.2984 - accuracy: 0.9178 - precision: 0.9548 - recall: 0.8682 - f1_score: 0.9187\n",
      "Epoch 41: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 18s 104ms/step - loss: 0.2984 - accuracy: 0.9178 - precision: 0.9548 - recall: 0.8682 - f1_score: 0.9187 - val_loss: 0.2886 - val_accuracy: 0.9322 - val_precision: 0.9310 - val_recall: 0.9153 - val_f1_score: 0.9286 - lr: 6.6897e-05\n",
      "Epoch 42/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.2528 - accuracy: 0.9250 - precision: 0.9638 - recall: 0.9008 - f1_score: 0.9259\n",
      "Epoch 42: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 22s 127ms/step - loss: 0.2528 - accuracy: 0.9250 - precision: 0.9638 - recall: 0.9008 - f1_score: 0.9259 - val_loss: 0.2868 - val_accuracy: 0.8814 - val_precision: 0.8966 - val_recall: 0.8814 - val_f1_score: 0.8837 - lr: 6.6228e-05\n",
      "Epoch 43/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.2514 - accuracy: 0.9287 - precision: 0.9727 - recall: 0.9045 - f1_score: 0.9285\n",
      "Epoch 43: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 19s 107ms/step - loss: 0.2514 - accuracy: 0.9287 - precision: 0.9727 - recall: 0.9045 - f1_score: 0.9285 - val_loss: 0.2783 - val_accuracy: 0.8983 - val_precision: 0.9464 - val_recall: 0.8983 - val_f1_score: 0.8990 - lr: 6.5566e-05\n",
      "Epoch 44/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.2628 - accuracy: 0.9197 - precision: 0.9629 - recall: 0.8844 - f1_score: 0.9208\n",
      "Epoch 44: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 18s 104ms/step - loss: 0.2626 - accuracy: 0.9202 - precision: 0.9631 - recall: 0.8839 - f1_score: 0.9212 - val_loss: 0.2976 - val_accuracy: 0.8814 - val_precision: 0.9273 - val_recall: 0.8644 - val_f1_score: 0.8786 - lr: 6.4910e-05\n",
      "Epoch 45/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.2658 - accuracy: 0.9202 - precision: 0.9620 - recall: 0.8875 - f1_score: 0.9209\n",
      "Epoch 45: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 20s 115ms/step - loss: 0.2658 - accuracy: 0.9202 - precision: 0.9620 - recall: 0.8875 - f1_score: 0.9209 - val_loss: 0.3494 - val_accuracy: 0.8644 - val_precision: 0.8772 - val_recall: 0.8475 - val_f1_score: 0.8514 - lr: 6.4261e-05\n",
      "Epoch 46/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.2390 - accuracy: 0.9335 - precision: 0.9677 - recall: 0.9057 - f1_score: 0.9337\n",
      "Epoch 46: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 21s 118ms/step - loss: 0.2390 - accuracy: 0.9335 - precision: 0.9677 - recall: 0.9057 - f1_score: 0.9337 - val_loss: 0.3303 - val_accuracy: 0.8983 - val_precision: 0.8947 - val_recall: 0.8644 - val_f1_score: 0.8952 - lr: 6.3619e-05\n",
      "Epoch 47/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.2456 - accuracy: 0.9270 - precision: 0.9649 - recall: 0.9027 - f1_score: 0.9276\n",
      "Epoch 47: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 18s 105ms/step - loss: 0.2443 - accuracy: 0.9274 - precision: 0.9651 - recall: 0.9033 - f1_score: 0.9281 - val_loss: 0.3246 - val_accuracy: 0.8814 - val_precision: 0.8947 - val_recall: 0.8644 - val_f1_score: 0.8786 - lr: 6.2982e-05\n",
      "Epoch 48/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.2617 - accuracy: 0.9319 - precision: 0.9676 - recall: 0.9088 - f1_score: 0.9325\n",
      "Epoch 48: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 23s 131ms/step - loss: 0.2607 - accuracy: 0.9323 - precision: 0.9678 - recall: 0.9093 - f1_score: 0.9330 - val_loss: 0.3079 - val_accuracy: 0.9153 - val_precision: 0.9138 - val_recall: 0.8983 - val_f1_score: 0.9137 - lr: 6.2353e-05\n",
      "Epoch 49/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.2328 - accuracy: 0.9323 - precision: 0.9591 - recall: 0.9069 - f1_score: 0.9322\n",
      "Epoch 49: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 19s 105ms/step - loss: 0.2328 - accuracy: 0.9323 - precision: 0.9591 - recall: 0.9069 - f1_score: 0.9322 - val_loss: 0.3130 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8970 - lr: 6.1729e-05\n",
      "Epoch 50/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1920 - accuracy: 0.9577 - precision: 0.9771 - recall: 0.9299 - f1_score: 0.9582\n",
      "Epoch 50: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 22s 123ms/step - loss: 0.1920 - accuracy: 0.9577 - precision: 0.9771 - recall: 0.9299 - f1_score: 0.9582 - val_loss: 0.3567 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8970 - lr: 6.1112e-05\n",
      "Epoch 51/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.2191 - accuracy: 0.9380 - precision: 0.9611 - recall: 0.9015 - f1_score: 0.9383\n",
      "Epoch 51: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 22s 124ms/step - loss: 0.2187 - accuracy: 0.9383 - precision: 0.9613 - recall: 0.9008 - f1_score: 0.9384 - val_loss: 0.3383 - val_accuracy: 0.8983 - val_precision: 0.8966 - val_recall: 0.8814 - val_f1_score: 0.8970 - lr: 6.0501e-05\n",
      "Epoch 52/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.2606 - accuracy: 0.9319 - precision: 0.9608 - recall: 0.8942 - f1_score: 0.9318\n",
      "Epoch 52: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 21s 122ms/step - loss: 0.2591 - accuracy: 0.9323 - precision: 0.9610 - recall: 0.8948 - f1_score: 0.9323 - val_loss: 0.3511 - val_accuracy: 0.8814 - val_precision: 0.8947 - val_recall: 0.8644 - val_f1_score: 0.8799 - lr: 5.9896e-05\n",
      "Epoch 53/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1943 - accuracy: 0.9541 - precision: 0.9685 - recall: 0.9299 - f1_score: 0.9537\n",
      "Epoch 53: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 21s 119ms/step - loss: 0.1943 - accuracy: 0.9541 - precision: 0.9685 - recall: 0.9299 - f1_score: 0.9537 - val_loss: 0.3635 - val_accuracy: 0.8983 - val_precision: 0.8947 - val_recall: 0.8644 - val_f1_score: 0.8952 - lr: 5.9297e-05\n",
      "Epoch 54/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.2199 - accuracy: 0.9383 - precision: 0.9631 - recall: 0.9154 - f1_score: 0.9387\n",
      "Epoch 54: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 21s 120ms/step - loss: 0.2199 - accuracy: 0.9383 - precision: 0.9631 - recall: 0.9154 - f1_score: 0.9387 - val_loss: 0.3585 - val_accuracy: 0.8983 - val_precision: 0.8966 - val_recall: 0.8814 - val_f1_score: 0.8952 - lr: 5.8704e-05\n",
      "Epoch 55/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1740 - accuracy: 0.9504 - precision: 0.9721 - recall: 0.9274 - f1_score: 0.9510\n",
      "Epoch 55: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 19s 108ms/step - loss: 0.1740 - accuracy: 0.9504 - precision: 0.9721 - recall: 0.9274 - f1_score: 0.9510 - val_loss: 0.3593 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8952 - lr: 5.8117e-05\n",
      "Epoch 56/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.2035 - accuracy: 0.9404 - precision: 0.9632 - recall: 0.9234 - f1_score: 0.9412\n",
      "Epoch 56: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 18s 105ms/step - loss: 0.2026 - accuracy: 0.9407 - precision: 0.9634 - recall: 0.9238 - f1_score: 0.9415 - val_loss: 0.3683 - val_accuracy: 0.8983 - val_precision: 0.9138 - val_recall: 0.8983 - val_f1_score: 0.8965 - lr: 5.7535e-05\n",
      "Epoch 57/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1882 - accuracy: 0.9420 - precision: 0.9707 - recall: 0.9214 - f1_score: 0.9425\n",
      "Epoch 57: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 18s 102ms/step - loss: 0.1882 - accuracy: 0.9420 - precision: 0.9707 - recall: 0.9214 - f1_score: 0.9425 - val_loss: 0.3510 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8952 - lr: 5.6960e-05\n",
      "Epoch 58/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.1995 - accuracy: 0.9513 - precision: 0.9757 - recall: 0.9270 - f1_score: 0.9521\n",
      "Epoch 58: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 21s 119ms/step - loss: 0.1983 - accuracy: 0.9516 - precision: 0.9758 - recall: 0.9274 - f1_score: 0.9524 - val_loss: 0.3702 - val_accuracy: 0.8983 - val_precision: 0.8966 - val_recall: 0.8814 - val_f1_score: 0.8965 - lr: 5.6391e-05\n",
      "Epoch 59/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1765 - accuracy: 0.9541 - precision: 0.9724 - recall: 0.9359 - f1_score: 0.9548\n",
      "Epoch 59: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 21s 119ms/step - loss: 0.1765 - accuracy: 0.9541 - precision: 0.9724 - recall: 0.9359 - f1_score: 0.9548 - val_loss: 0.3603 - val_accuracy: 0.8983 - val_precision: 0.8983 - val_recall: 0.8983 - val_f1_score: 0.8965 - lr: 5.5827e-05\n",
      "Epoch 60/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1969 - accuracy: 0.9456 - precision: 0.9717 - recall: 0.9129 - f1_score: 0.9461\n",
      "Epoch 60: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 21s 120ms/step - loss: 0.1969 - accuracy: 0.9456 - precision: 0.9717 - recall: 0.9129 - f1_score: 0.9461 - val_loss: 0.3507 - val_accuracy: 0.8983 - val_precision: 0.8966 - val_recall: 0.8814 - val_f1_score: 0.8952 - lr: 5.5268e-05\n",
      "Epoch 61/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1897 - accuracy: 0.9541 - precision: 0.9724 - recall: 0.9359 - f1_score: 0.9539\n",
      "Epoch 61: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 19s 106ms/step - loss: 0.1897 - accuracy: 0.9541 - precision: 0.9724 - recall: 0.9359 - f1_score: 0.9539 - val_loss: 0.3418 - val_accuracy: 0.8644 - val_precision: 0.8644 - val_recall: 0.8644 - val_f1_score: 0.8652 - lr: 5.4716e-05\n",
      "Epoch 62/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.1959 - accuracy: 0.9404 - precision: 0.9607 - recall: 0.9221 - f1_score: 0.9412\n",
      "Epoch 62: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 19s 106ms/step - loss: 0.1949 - accuracy: 0.9407 - precision: 0.9610 - recall: 0.9226 - f1_score: 0.9415 - val_loss: 0.3362 - val_accuracy: 0.8814 - val_precision: 0.8966 - val_recall: 0.8814 - val_f1_score: 0.8781 - lr: 5.4169e-05\n",
      "Epoch 63/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.1986 - accuracy: 0.9440 - precision: 0.9646 - recall: 0.9294 - f1_score: 0.9443\n",
      "Epoch 63: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 19s 106ms/step - loss: 0.1977 - accuracy: 0.9444 - precision: 0.9649 - recall: 0.9299 - f1_score: 0.9446 - val_loss: 0.3693 - val_accuracy: 0.8814 - val_precision: 0.9123 - val_recall: 0.8814 - val_f1_score: 0.8805 - lr: 5.3627e-05\n",
      "Epoch 64/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.2021 - accuracy: 0.9492 - precision: 0.9649 - recall: 0.9311 - f1_score: 0.9492\n",
      "Epoch 64: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 21s 120ms/step - loss: 0.2021 - accuracy: 0.9492 - precision: 0.9649 - recall: 0.9311 - f1_score: 0.9492 - val_loss: 0.3850 - val_accuracy: 0.8644 - val_precision: 0.8947 - val_recall: 0.8644 - val_f1_score: 0.8648 - lr: 5.3091e-05\n",
      "Epoch 65/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.2044 - accuracy: 0.9477 - precision: 0.9728 - recall: 0.9148 - f1_score: 0.9473\n",
      "Epoch 65: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 20s 116ms/step - loss: 0.2036 - accuracy: 0.9480 - precision: 0.9730 - recall: 0.9154 - f1_score: 0.9477 - val_loss: 0.4125 - val_accuracy: 0.8814 - val_precision: 0.8814 - val_recall: 0.8814 - val_f1_score: 0.8819 - lr: 5.2560e-05\n",
      "Epoch 66/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.2115 - accuracy: 0.9420 - precision: 0.9679 - recall: 0.9117 - f1_score: 0.9417\n",
      "Epoch 66: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 21s 119ms/step - loss: 0.2115 - accuracy: 0.9420 - precision: 0.9679 - recall: 0.9117 - f1_score: 0.9417 - val_loss: 0.3886 - val_accuracy: 0.8644 - val_precision: 0.8596 - val_recall: 0.8305 - val_f1_score: 0.8652 - lr: 5.2034e-05\n",
      "Epoch 67/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.1433 - accuracy: 0.9637 - precision: 0.9848 - recall: 0.9432 - f1_score: 0.9643\n",
      "Epoch 67: val_loss did not improve from 0.23692\n",
      "165/165 [==============================] - 19s 109ms/step - loss: 0.1433 - accuracy: 0.9637 - precision: 0.9848 - recall: 0.9432 - f1_score: 0.9643 - val_loss: 0.3885 - val_accuracy: 0.8644 - val_precision: 0.8621 - val_recall: 0.8475 - val_f1_score: 0.8652 - lr: 5.1514e-05\n",
      "Epoch 67: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=\n",
    "         train_generator.samples/train_generator.batch_size,\n",
    "      epochs=100,\n",
    "      validation_data=validation_generator, \n",
    "      validation_steps=\n",
    "         validation_generator.samples/validation_generator.batch_size,\n",
    "      verbose=1,\n",
    "      workers = 10,\n",
    "      use_multiprocessing = True,\n",
    "      callbacks = [checkpoint, es, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1b91678",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "f1b91678",
    "outputId": "7b8b1eae-fd79-4ba9-b09c-ce9ff1b41439"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_results(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5046a8f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5046a8f5",
    "outputId": "9d4d34ac-0a2f-4ebf-f43e-e042ae9211ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 290 non-validated image filenames belonging to 20 classes.\n",
      "Loading model efficient_b0_best_model.hdf5\n",
      "58/58 [==============================] - 216s 4s/step - loss: 0.2162 - accuracy: 0.9379 - precision: 0.9638 - recall: 0.9172 - f1_score: 0.9382\n",
      "Test Loss 0.21617476642131805\n",
      "Test Accuracy 0.9379310607910156\n",
      "Test Precision 0.9637681245803833\n",
      "Test Recall 0.9172413945198059\n",
      "Test F1 Score 0.9381998\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "validate_filenames=False,\n",
    "dataframe = test_df,\n",
    "directory = '',\n",
    "x_col = 'Images',\n",
    "y_col = 'Class',\n",
    "class_mode = 'categorical',\n",
    "batch_size = 5,\n",
    "target_size=(224,224))\n",
    "\n",
    "model = load_model(filepath)\n",
    "print(f\"Loading model {filepath}\")\n",
    "loss, accuracy, precision, recall, f1_score = model.evaluate(test_generator, verbose = 1)\n",
    "print(\"Test Loss\", loss)\n",
    "print(\"Test Accuracy\", accuracy)\n",
    "print(\"Test Precision\", precision)\n",
    "print(\"Test Recall\", recall)\n",
    "print(\"Test F1 Score\", f1_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c89968b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5c89968b",
    "outputId": "c119cfe6-f664-4589-cfbf-056054be9c8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 4s 0us/step\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fc8e69025e0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc8e69027c0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc8e6902700> False\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7fc9ef26d040> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc8e690fb20> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc8e690f0a0> False\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7fc8e6902e80> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc8e6917ac0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc8e691b370> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc8e691b0d0> False\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7fc8e691b7c0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc8e6925160> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc8e6925e20> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc8e6925b80> False\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7fc8e6921ac0> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc8e692ed90> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc8e692b310> False\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7fc8e6925580> False\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7fc8e692e9d0> True\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 362)               9082218   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 362)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 362)              1448      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 20)                7260      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,805,614\n",
      "Trainable params: 9,090,202\n",
      "Non-trainable params: 14,715,412\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_conv = vgg16.VGG16(weights = 'imagenet', include_top = False, input_shape=(224, 224, 3))\n",
    "for layer in vgg_conv.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in vgg_conv.layers:\n",
    "    print(layer, layer.trainable)\n",
    "filepath = 'vgg_16_best_model.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, \n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30)\n",
    "model = Sequential()\n",
    "model.add(vgg_conv)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(362, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(20, activation='softmax'))\n",
    "opt = Adam()\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tfa.metrics.F1Score(num_classes=20)])\n",
    " \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "192b746f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "192b746f",
    "outputId": "4a0742e0-1b07-44a4-a937-bc259e6056e7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 3.0205 - accuracy: 0.1536 - precision_1: 0.3253 - recall_1: 0.0326 - f1_score: 0.1514\n",
      "Epoch 1: val_loss improved from inf to 1.66463, saving model to vgg_16_best_model.hdf5\n",
      "165/165 [==============================] - 26s 135ms/step - loss: 3.0205 - accuracy: 0.1536 - precision_1: 0.3253 - recall_1: 0.0326 - f1_score: 0.1514 - val_loss: 1.6646 - val_accuracy: 0.5593 - val_precision_1: 0.7692 - val_recall_1: 0.3390 - val_f1_score: 0.4900 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 2.0817 - accuracy: 0.3615 - precision_1: 0.6353 - recall_1: 0.1306 - f1_score: 0.3566\n",
      "Epoch 2: val_loss improved from 1.66463 to 1.20591, saving model to vgg_16_best_model.hdf5\n",
      "165/165 [==============================] - 20s 116ms/step - loss: 2.0817 - accuracy: 0.3615 - precision_1: 0.6353 - recall_1: 0.1306 - f1_score: 0.3566 - val_loss: 1.2059 - val_accuracy: 0.6102 - val_precision_1: 0.7500 - val_recall_1: 0.5085 - val_f1_score: 0.5762 - lr: 9.9000e-05\n",
      "Epoch 3/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 1.8458 - accuracy: 0.4414 - precision_1: 0.7722 - recall_1: 0.2213 - f1_score: 0.4358\n",
      "Epoch 3: val_loss improved from 1.20591 to 1.12520, saving model to vgg_16_best_model.hdf5\n",
      "165/165 [==============================] - 21s 119ms/step - loss: 1.8458 - accuracy: 0.4414 - precision_1: 0.7722 - recall_1: 0.2213 - f1_score: 0.4358 - val_loss: 1.1252 - val_accuracy: 0.6271 - val_precision_1: 0.7674 - val_recall_1: 0.5593 - val_f1_score: 0.6124 - lr: 9.8010e-05\n",
      "Epoch 4/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 1.6265 - accuracy: 0.5163 - precision_1: 0.7757 - recall_1: 0.3011 - f1_score: 0.5090\n",
      "Epoch 4: val_loss improved from 1.12520 to 1.01940, saving model to vgg_16_best_model.hdf5\n",
      "165/165 [==============================] - 19s 108ms/step - loss: 1.6265 - accuracy: 0.5163 - precision_1: 0.7757 - recall_1: 0.3011 - f1_score: 0.5090 - val_loss: 1.0194 - val_accuracy: 0.6441 - val_precision_1: 0.7619 - val_recall_1: 0.5424 - val_f1_score: 0.6345 - lr: 9.7030e-05\n",
      "Epoch 5/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 1.4752 - accuracy: 0.5547 - precision_1: 0.7906 - recall_1: 0.3674 - f1_score: 0.5487\n",
      "Epoch 5: val_loss improved from 1.01940 to 0.93475, saving model to vgg_16_best_model.hdf5\n",
      "165/165 [==============================] - 23s 130ms/step - loss: 1.4738 - accuracy: 0.5550 - precision_1: 0.7902 - recall_1: 0.3688 - f1_score: 0.5492 - val_loss: 0.9348 - val_accuracy: 0.7119 - val_precision_1: 0.8293 - val_recall_1: 0.5763 - val_f1_score: 0.7100 - lr: 9.6060e-05\n",
      "Epoch 6/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 1.3005 - accuracy: 0.6083 - precision_1: 0.8271 - recall_1: 0.3783 - f1_score: 0.6064\n",
      "Epoch 6: val_loss did not improve from 0.93475\n",
      "165/165 [==============================] - 18s 103ms/step - loss: 1.3030 - accuracy: 0.6070 - precision_1: 0.8254 - recall_1: 0.3773 - f1_score: 0.6052 - val_loss: 0.9959 - val_accuracy: 0.6610 - val_precision_1: 0.8222 - val_recall_1: 0.6271 - val_f1_score: 0.6550 - lr: 9.5099e-05\n",
      "Epoch 7/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 1.1966 - accuracy: 0.6496 - precision_1: 0.8421 - recall_1: 0.4282 - f1_score: 0.6471\n",
      "Epoch 7: val_loss improved from 0.93475 to 0.87896, saving model to vgg_16_best_model.hdf5\n",
      "165/165 [==============================] - 19s 104ms/step - loss: 1.1939 - accuracy: 0.6505 - precision_1: 0.8436 - recall_1: 0.4305 - f1_score: 0.6481 - val_loss: 0.8790 - val_accuracy: 0.6780 - val_precision_1: 0.7917 - val_recall_1: 0.6441 - val_f1_score: 0.6656 - lr: 9.4148e-05\n",
      "Epoch 8/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 1.1149 - accuracy: 0.6521 - precision_1: 0.8457 - recall_1: 0.4866 - f1_score: 0.6540\n",
      "Epoch 8: val_loss improved from 0.87896 to 0.81593, saving model to vgg_16_best_model.hdf5\n",
      "165/165 [==============================] - 18s 103ms/step - loss: 1.1119 - accuracy: 0.6542 - precision_1: 0.8466 - recall_1: 0.4873 - f1_score: 0.6560 - val_loss: 0.8159 - val_accuracy: 0.6949 - val_precision_1: 0.8605 - val_recall_1: 0.6271 - val_f1_score: 0.6907 - lr: 9.3207e-05\n",
      "Epoch 9/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 1.1059 - accuracy: 0.6771 - precision_1: 0.8638 - recall_1: 0.4909 - f1_score: 0.6767\n",
      "Epoch 9: val_loss did not improve from 0.81593\n",
      "165/165 [==============================] - 21s 119ms/step - loss: 1.1059 - accuracy: 0.6771 - precision_1: 0.8638 - recall_1: 0.4909 - f1_score: 0.6767 - val_loss: 0.8217 - val_accuracy: 0.7458 - val_precision_1: 0.8125 - val_recall_1: 0.6610 - val_f1_score: 0.7362 - lr: 9.2274e-05\n",
      "Epoch 10/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 1.0448 - accuracy: 0.6868 - precision_1: 0.8592 - recall_1: 0.5091 - f1_score: 0.6840\n",
      "Epoch 10: val_loss improved from 0.81593 to 0.80660, saving model to vgg_16_best_model.hdf5\n",
      "165/165 [==============================] - 21s 122ms/step - loss: 1.0448 - accuracy: 0.6868 - precision_1: 0.8592 - recall_1: 0.5091 - f1_score: 0.6840 - val_loss: 0.8066 - val_accuracy: 0.7288 - val_precision_1: 0.8542 - val_recall_1: 0.6949 - val_f1_score: 0.7204 - lr: 9.1352e-05\n",
      "Epoch 11/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.9461 - accuracy: 0.7141 - precision_1: 0.9078 - recall_1: 0.5511 - f1_score: 0.7144\n",
      "Epoch 11: val_loss improved from 0.80660 to 0.75433, saving model to vgg_16_best_model.hdf5\n",
      "165/165 [==============================] - 18s 104ms/step - loss: 0.9432 - accuracy: 0.7158 - precision_1: 0.9085 - recall_1: 0.5526 - f1_score: 0.7158 - val_loss: 0.7543 - val_accuracy: 0.7797 - val_precision_1: 0.8636 - val_recall_1: 0.6441 - val_f1_score: 0.7611 - lr: 9.0438e-05\n",
      "Epoch 12/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.9291 - accuracy: 0.7122 - precision_1: 0.8794 - recall_1: 0.5732 - f1_score: 0.7129\n",
      "Epoch 12: val_loss improved from 0.75433 to 0.71062, saving model to vgg_16_best_model.hdf5\n",
      "165/165 [==============================] - 22s 128ms/step - loss: 0.9291 - accuracy: 0.7122 - precision_1: 0.8794 - recall_1: 0.5732 - f1_score: 0.7129 - val_loss: 0.7106 - val_accuracy: 0.8136 - val_precision_1: 0.9184 - val_recall_1: 0.7627 - val_f1_score: 0.7999 - lr: 8.9534e-05\n",
      "Epoch 13/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.8550 - accuracy: 0.7433 - precision_1: 0.9357 - recall_1: 0.5839 - f1_score: 0.7426\n",
      "Epoch 13: val_loss did not improve from 0.71062\n",
      "165/165 [==============================] - 18s 101ms/step - loss: 0.8575 - accuracy: 0.7424 - precision_1: 0.9342 - recall_1: 0.5840 - f1_score: 0.7417 - val_loss: 0.8002 - val_accuracy: 0.7797 - val_precision_1: 0.8958 - val_recall_1: 0.7288 - val_f1_score: 0.7699 - lr: 8.8638e-05\n",
      "Epoch 14/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.8449 - accuracy: 0.7654 - precision_1: 0.9007 - recall_1: 0.5925 - f1_score: 0.7644\n",
      "Epoch 14: val_loss did not improve from 0.71062\n",
      "165/165 [==============================] - 18s 103ms/step - loss: 0.8449 - accuracy: 0.7654 - precision_1: 0.9007 - recall_1: 0.5925 - f1_score: 0.7644 - val_loss: 0.7293 - val_accuracy: 0.8136 - val_precision_1: 0.9130 - val_recall_1: 0.7119 - val_f1_score: 0.7993 - lr: 8.7752e-05\n",
      "Epoch 15/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.8357 - accuracy: 0.7678 - precision_1: 0.9027 - recall_1: 0.6167 - f1_score: 0.7671\n",
      "Epoch 15: val_loss did not improve from 0.71062\n",
      "165/165 [==============================] - 21s 119ms/step - loss: 0.8357 - accuracy: 0.7678 - precision_1: 0.9027 - recall_1: 0.6167 - f1_score: 0.7671 - val_loss: 0.7861 - val_accuracy: 0.7797 - val_precision_1: 0.8696 - val_recall_1: 0.6780 - val_f1_score: 0.7737 - lr: 8.6875e-05\n",
      "Epoch 16/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.8304 - accuracy: 0.7521 - precision_1: 0.8995 - recall_1: 0.5949 - f1_score: 0.7520\n",
      "Epoch 16: val_loss did not improve from 0.71062\n",
      "165/165 [==============================] - 21s 121ms/step - loss: 0.8304 - accuracy: 0.7521 - precision_1: 0.8995 - recall_1: 0.5949 - f1_score: 0.7520 - val_loss: 0.8143 - val_accuracy: 0.7627 - val_precision_1: 0.8511 - val_recall_1: 0.6780 - val_f1_score: 0.7515 - lr: 8.6006e-05\n",
      "Epoch 17/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.8345 - accuracy: 0.7582 - precision_1: 0.8996 - recall_1: 0.6179 - f1_score: 0.7598\n",
      "Epoch 17: val_loss did not improve from 0.71062\n",
      "165/165 [==============================] - 18s 101ms/step - loss: 0.8345 - accuracy: 0.7582 - precision_1: 0.8996 - recall_1: 0.6179 - f1_score: 0.7598 - val_loss: 0.8053 - val_accuracy: 0.6949 - val_precision_1: 0.7917 - val_recall_1: 0.6441 - val_f1_score: 0.6926 - lr: 8.5146e-05\n",
      "Epoch 18/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.8207 - accuracy: 0.7739 - precision_1: 0.8952 - recall_1: 0.6094 - f1_score: 0.7732\n",
      "Epoch 18: val_loss did not improve from 0.71062\n",
      "165/165 [==============================] - 20s 111ms/step - loss: 0.8207 - accuracy: 0.7739 - precision_1: 0.8952 - recall_1: 0.6094 - f1_score: 0.7732 - val_loss: 0.7475 - val_accuracy: 0.7627 - val_precision_1: 0.8696 - val_recall_1: 0.6780 - val_f1_score: 0.7515 - lr: 8.4294e-05\n",
      "Epoch 19/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.7396 - accuracy: 0.7836 - precision_1: 0.9105 - recall_1: 0.6518 - f1_score: 0.7829\n",
      "Epoch 19: val_loss improved from 0.71062 to 0.69723, saving model to vgg_16_best_model.hdf5\n",
      "165/165 [==============================] - 21s 119ms/step - loss: 0.7396 - accuracy: 0.7836 - precision_1: 0.9105 - recall_1: 0.6518 - f1_score: 0.7829 - val_loss: 0.6972 - val_accuracy: 0.7966 - val_precision_1: 0.8980 - val_recall_1: 0.7458 - val_f1_score: 0.7781 - lr: 8.3451e-05\n",
      "Epoch 20/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.7046 - accuracy: 0.7932 - precision_1: 0.9201 - recall_1: 0.6687 - f1_score: 0.7923\n",
      "Epoch 20: val_loss did not improve from 0.69723\n",
      "165/165 [==============================] - 18s 102ms/step - loss: 0.7046 - accuracy: 0.7932 - precision_1: 0.9201 - recall_1: 0.6687 - f1_score: 0.7923 - val_loss: 0.7195 - val_accuracy: 0.7288 - val_precision_1: 0.8750 - val_recall_1: 0.7119 - val_f1_score: 0.7098 - lr: 8.2617e-05\n",
      "Epoch 21/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.7467 - accuracy: 0.7787 - precision_1: 0.9159 - recall_1: 0.6324 - f1_score: 0.7794\n",
      "Epoch 21: val_loss improved from 0.69723 to 0.69606, saving model to vgg_16_best_model.hdf5\n",
      "165/165 [==============================] - 19s 111ms/step - loss: 0.7467 - accuracy: 0.7787 - precision_1: 0.9159 - recall_1: 0.6324 - f1_score: 0.7794 - val_loss: 0.6961 - val_accuracy: 0.8136 - val_precision_1: 0.9200 - val_recall_1: 0.7797 - val_f1_score: 0.7936 - lr: 8.1791e-05\n",
      "Epoch 22/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.7041 - accuracy: 0.8102 - precision_1: 0.9128 - recall_1: 0.6711 - f1_score: 0.8093\n",
      "Epoch 22: val_loss did not improve from 0.69606\n",
      "165/165 [==============================] - 21s 119ms/step - loss: 0.7041 - accuracy: 0.8102 - precision_1: 0.9128 - recall_1: 0.6711 - f1_score: 0.8093 - val_loss: 0.7473 - val_accuracy: 0.7797 - val_precision_1: 0.8980 - val_recall_1: 0.7458 - val_f1_score: 0.7619 - lr: 8.0973e-05\n",
      "Epoch 23/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.7395 - accuracy: 0.7944 - precision_1: 0.9100 - recall_1: 0.6723 - f1_score: 0.7924\n",
      "Epoch 23: val_loss improved from 0.69606 to 0.67727, saving model to vgg_16_best_model.hdf5\n",
      "165/165 [==============================] - 21s 117ms/step - loss: 0.7395 - accuracy: 0.7944 - precision_1: 0.9100 - recall_1: 0.6723 - f1_score: 0.7924 - val_loss: 0.6773 - val_accuracy: 0.8136 - val_precision_1: 0.9200 - val_recall_1: 0.7797 - val_f1_score: 0.7936 - lr: 8.0163e-05\n",
      "Epoch 24/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.6757 - accuracy: 0.7993 - precision_1: 0.9244 - recall_1: 0.6953 - f1_score: 0.7999\n",
      "Epoch 24: val_loss improved from 0.67727 to 0.66446, saving model to vgg_16_best_model.hdf5\n",
      "165/165 [==============================] - 18s 107ms/step - loss: 0.6757 - accuracy: 0.7993 - precision_1: 0.9244 - recall_1: 0.6953 - f1_score: 0.7999 - val_loss: 0.6645 - val_accuracy: 0.7966 - val_precision_1: 0.9200 - val_recall_1: 0.7797 - val_f1_score: 0.7744 - lr: 7.9361e-05\n",
      "Epoch 25/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.6826 - accuracy: 0.8114 - precision_1: 0.9135 - recall_1: 0.7068 - f1_score: 0.8114\n",
      "Epoch 25: val_loss improved from 0.66446 to 0.64024, saving model to vgg_16_best_model.hdf5\n",
      "165/165 [==============================] - 20s 114ms/step - loss: 0.6833 - accuracy: 0.8114 - precision_1: 0.9141 - recall_1: 0.7074 - f1_score: 0.8112 - val_loss: 0.6402 - val_accuracy: 0.8136 - val_precision_1: 0.9388 - val_recall_1: 0.7797 - val_f1_score: 0.8031 - lr: 7.8568e-05\n",
      "Epoch 26/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.6619 - accuracy: 0.8273 - precision_1: 0.9157 - recall_1: 0.7007 - f1_score: 0.8280\n",
      "Epoch 26: val_loss did not improve from 0.64024\n",
      "165/165 [==============================] - 21s 118ms/step - loss: 0.6585 - accuracy: 0.8283 - precision_1: 0.9164 - recall_1: 0.7025 - f1_score: 0.8288 - val_loss: 0.6598 - val_accuracy: 0.8136 - val_precision_1: 0.9216 - val_recall_1: 0.7966 - val_f1_score: 0.8056 - lr: 7.7782e-05\n",
      "Epoch 27/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.6381 - accuracy: 0.8198 - precision_1: 0.9246 - recall_1: 0.7122 - f1_score: 0.8175\n",
      "Epoch 27: val_loss did not improve from 0.64024\n",
      "165/165 [==============================] - 18s 103ms/step - loss: 0.6381 - accuracy: 0.8198 - precision_1: 0.9246 - recall_1: 0.7122 - f1_score: 0.8175 - val_loss: 0.6733 - val_accuracy: 0.8305 - val_precision_1: 0.9412 - val_recall_1: 0.8136 - val_f1_score: 0.8175 - lr: 7.7004e-05\n",
      "Epoch 28/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.6395 - accuracy: 0.8273 - precision_1: 0.9330 - recall_1: 0.7117 - f1_score: 0.8269\n",
      "Epoch 28: val_loss did not improve from 0.64024\n",
      "165/165 [==============================] - 18s 103ms/step - loss: 0.6377 - accuracy: 0.8283 - precision_1: 0.9334 - recall_1: 0.7122 - f1_score: 0.8282 - val_loss: 0.7668 - val_accuracy: 0.8136 - val_precision_1: 0.9149 - val_recall_1: 0.7288 - val_f1_score: 0.8050 - lr: 7.6234e-05\n",
      "Epoch 29/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.6010 - accuracy: 0.8392 - precision_1: 0.9321 - recall_1: 0.7304 - f1_score: 0.8393\n",
      "Epoch 29: val_loss did not improve from 0.64024\n",
      "165/165 [==============================] - 21s 121ms/step - loss: 0.6010 - accuracy: 0.8392 - precision_1: 0.9321 - recall_1: 0.7304 - f1_score: 0.8393 - val_loss: 0.7319 - val_accuracy: 0.7797 - val_precision_1: 0.8980 - val_recall_1: 0.7458 - val_f1_score: 0.7729 - lr: 7.5472e-05\n",
      "Epoch 30/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.6523 - accuracy: 0.8151 - precision_1: 0.9094 - recall_1: 0.7202 - f1_score: 0.8129\n",
      "Epoch 30: val_loss did not improve from 0.64024\n",
      "165/165 [==============================] - 18s 101ms/step - loss: 0.6515 - accuracy: 0.8162 - precision_1: 0.9098 - recall_1: 0.7195 - f1_score: 0.8143 - val_loss: 0.7231 - val_accuracy: 0.7797 - val_precision_1: 0.8824 - val_recall_1: 0.7627 - val_f1_score: 0.7770 - lr: 7.4717e-05\n",
      "Epoch 31/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.5391 - accuracy: 0.8528 - precision_1: 0.9413 - recall_1: 0.7603 - f1_score: 0.8521\n",
      "Epoch 31: val_loss did not improve from 0.64024\n",
      "165/165 [==============================] - 18s 99ms/step - loss: 0.5388 - accuracy: 0.8525 - precision_1: 0.9415 - recall_1: 0.7594 - f1_score: 0.8520 - val_loss: 0.7087 - val_accuracy: 0.7797 - val_precision_1: 0.8627 - val_recall_1: 0.7458 - val_f1_score: 0.7769 - lr: 7.3970e-05\n",
      "Epoch 32/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.5912 - accuracy: 0.8309 - precision_1: 0.9255 - recall_1: 0.7105 - f1_score: 0.8311\n",
      "Epoch 32: val_loss did not improve from 0.64024\n",
      "165/165 [==============================] - 23s 130ms/step - loss: 0.5906 - accuracy: 0.8307 - precision_1: 0.9245 - recall_1: 0.7110 - f1_score: 0.8304 - val_loss: 0.7668 - val_accuracy: 0.7627 - val_precision_1: 0.8627 - val_recall_1: 0.7458 - val_f1_score: 0.7598 - lr: 7.3230e-05\n",
      "Epoch 33/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.5374 - accuracy: 0.8537 - precision_1: 0.9365 - recall_1: 0.7485 - f1_score: 0.8546\n",
      "Epoch 33: val_loss did not improve from 0.64024\n",
      "165/165 [==============================] - 18s 104ms/step - loss: 0.5374 - accuracy: 0.8537 - precision_1: 0.9365 - recall_1: 0.7485 - f1_score: 0.8546 - val_loss: 0.7221 - val_accuracy: 0.7797 - val_precision_1: 0.8800 - val_recall_1: 0.7458 - val_f1_score: 0.7788 - lr: 7.2498e-05\n",
      "Epoch 34/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.5800 - accuracy: 0.8452 - precision_1: 0.9298 - recall_1: 0.7364 - f1_score: 0.8457\n",
      "Epoch 34: val_loss did not improve from 0.64024\n",
      "165/165 [==============================] - 18s 103ms/step - loss: 0.5800 - accuracy: 0.8452 - precision_1: 0.9298 - recall_1: 0.7364 - f1_score: 0.8457 - val_loss: 0.8043 - val_accuracy: 0.7458 - val_precision_1: 0.8776 - val_recall_1: 0.7288 - val_f1_score: 0.7377 - lr: 7.1773e-05\n",
      "Epoch 35/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.5160 - accuracy: 0.8573 - precision_1: 0.9563 - recall_1: 0.7666 - f1_score: 0.8584\n",
      "Epoch 35: val_loss did not improve from 0.64024\n",
      "165/165 [==============================] - 21s 121ms/step - loss: 0.5160 - accuracy: 0.8573 - precision_1: 0.9563 - recall_1: 0.7666 - f1_score: 0.8584 - val_loss: 0.7096 - val_accuracy: 0.7627 - val_precision_1: 0.8750 - val_recall_1: 0.7119 - val_f1_score: 0.7479 - lr: 7.1055e-05\n",
      "Epoch 36/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.6139 - accuracy: 0.8356 - precision_1: 0.9183 - recall_1: 0.7473 - f1_score: 0.8373\n",
      "Epoch 36: val_loss did not improve from 0.64024\n",
      "165/165 [==============================] - 20s 107ms/step - loss: 0.6139 - accuracy: 0.8356 - precision_1: 0.9183 - recall_1: 0.7473 - f1_score: 0.8373 - val_loss: 0.7154 - val_accuracy: 0.7627 - val_precision_1: 0.8800 - val_recall_1: 0.7458 - val_f1_score: 0.7612 - lr: 7.0345e-05\n",
      "Epoch 37/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.5441 - accuracy: 0.8476 - precision_1: 0.9331 - recall_1: 0.7594 - f1_score: 0.8467\n",
      "Epoch 37: val_loss did not improve from 0.64024\n",
      "165/165 [==============================] - 18s 103ms/step - loss: 0.5441 - accuracy: 0.8476 - precision_1: 0.9331 - recall_1: 0.7594 - f1_score: 0.8467 - val_loss: 0.6655 - val_accuracy: 0.7797 - val_precision_1: 0.8627 - val_recall_1: 0.7458 - val_f1_score: 0.7724 - lr: 6.9641e-05\n",
      "Epoch 38/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.4919 - accuracy: 0.8730 - precision_1: 0.9490 - recall_1: 0.7872 - f1_score: 0.8738\n",
      "Epoch 38: val_loss did not improve from 0.64024\n",
      "165/165 [==============================] - 18s 104ms/step - loss: 0.4919 - accuracy: 0.8730 - precision_1: 0.9490 - recall_1: 0.7872 - f1_score: 0.8738 - val_loss: 0.6955 - val_accuracy: 0.8136 - val_precision_1: 0.8542 - val_recall_1: 0.6949 - val_f1_score: 0.8124 - lr: 6.8945e-05\n",
      "Epoch 39/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.5254 - accuracy: 0.8622 - precision_1: 0.9447 - recall_1: 0.7848 - f1_score: 0.8620\n",
      "Epoch 39: val_loss did not improve from 0.64024\n",
      "165/165 [==============================] - 24s 137ms/step - loss: 0.5254 - accuracy: 0.8622 - precision_1: 0.9447 - recall_1: 0.7848 - f1_score: 0.8620 - val_loss: 0.9337 - val_accuracy: 0.7627 - val_precision_1: 0.8077 - val_recall_1: 0.7119 - val_f1_score: 0.7550 - lr: 6.8255e-05\n",
      "Epoch 40/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.4989 - accuracy: 0.8476 - precision_1: 0.9435 - recall_1: 0.7666 - f1_score: 0.8486\n",
      "Epoch 40: val_loss did not improve from 0.64024\n",
      "165/165 [==============================] - 18s 102ms/step - loss: 0.4989 - accuracy: 0.8476 - precision_1: 0.9435 - recall_1: 0.7666 - f1_score: 0.8486 - val_loss: 0.9607 - val_accuracy: 0.7797 - val_precision_1: 0.8333 - val_recall_1: 0.6780 - val_f1_score: 0.7719 - lr: 6.7573e-05\n",
      "Epoch 41/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.4595 - accuracy: 0.8723 - precision_1: 0.9564 - recall_1: 0.8005 - f1_score: 0.8712\n",
      "Epoch 41: val_loss did not improve from 0.64024\n",
      "165/165 [==============================] - 19s 106ms/step - loss: 0.4575 - accuracy: 0.8730 - precision_1: 0.9567 - recall_1: 0.8017 - f1_score: 0.8719 - val_loss: 0.7498 - val_accuracy: 0.8305 - val_precision_1: 0.8627 - val_recall_1: 0.7458 - val_f1_score: 0.8289 - lr: 6.6897e-05\n",
      "Epoch 42/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.5192 - accuracy: 0.8540 - precision_1: 0.9343 - recall_1: 0.7616 - f1_score: 0.8541\n",
      "Epoch 42: val_loss did not improve from 0.64024\n",
      "165/165 [==============================] - 22s 123ms/step - loss: 0.5166 - accuracy: 0.8549 - precision_1: 0.9348 - recall_1: 0.7630 - f1_score: 0.8551 - val_loss: 0.8092 - val_accuracy: 0.7797 - val_precision_1: 0.8400 - val_recall_1: 0.7119 - val_f1_score: 0.7807 - lr: 6.6228e-05\n",
      "Epoch 43/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.4484 - accuracy: 0.8742 - precision_1: 0.9460 - recall_1: 0.8053 - f1_score: 0.8745\n",
      "Epoch 43: val_loss improved from 0.64024 to 0.61097, saving model to vgg_16_best_model.hdf5\n",
      "165/165 [==============================] - 19s 107ms/step - loss: 0.4484 - accuracy: 0.8742 - precision_1: 0.9460 - recall_1: 0.8053 - f1_score: 0.8745 - val_loss: 0.6110 - val_accuracy: 0.8136 - val_precision_1: 0.8627 - val_recall_1: 0.7458 - val_f1_score: 0.8086 - lr: 6.5566e-05\n",
      "Epoch 44/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.4958 - accuracy: 0.8771 - precision_1: 0.9337 - recall_1: 0.7883 - f1_score: 0.8772\n",
      "Epoch 44: val_loss did not improve from 0.61097\n",
      "165/165 [==============================] - 18s 102ms/step - loss: 0.4942 - accuracy: 0.8779 - precision_1: 0.9342 - recall_1: 0.7896 - f1_score: 0.8780 - val_loss: 0.6530 - val_accuracy: 0.7627 - val_precision_1: 0.8571 - val_recall_1: 0.7119 - val_f1_score: 0.7632 - lr: 6.4910e-05\n",
      "Epoch 45/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.4418 - accuracy: 0.8747 - precision_1: 0.9224 - recall_1: 0.7956 - f1_score: 0.8756\n",
      "Epoch 45: val_loss did not improve from 0.61097\n",
      "165/165 [==============================] - 18s 101ms/step - loss: 0.4407 - accuracy: 0.8755 - precision_1: 0.9229 - recall_1: 0.7956 - f1_score: 0.8762 - val_loss: 0.6215 - val_accuracy: 0.8136 - val_precision_1: 0.8654 - val_recall_1: 0.7627 - val_f1_score: 0.8144 - lr: 6.4261e-05\n",
      "Epoch 46/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.4610 - accuracy: 0.8634 - precision_1: 0.9428 - recall_1: 0.7969 - f1_score: 0.8635\n",
      "Epoch 46: val_loss did not improve from 0.61097\n",
      "165/165 [==============================] - 21s 122ms/step - loss: 0.4610 - accuracy: 0.8634 - precision_1: 0.9428 - recall_1: 0.7969 - f1_score: 0.8635 - val_loss: 0.6618 - val_accuracy: 0.7966 - val_precision_1: 0.8958 - val_recall_1: 0.7288 - val_f1_score: 0.7794 - lr: 6.3619e-05\n",
      "Epoch 47/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.4195 - accuracy: 0.8808 - precision_1: 0.9399 - recall_1: 0.8187 - f1_score: 0.8801\n",
      "Epoch 47: val_loss did not improve from 0.61097\n",
      "165/165 [==============================] - 20s 111ms/step - loss: 0.4206 - accuracy: 0.8791 - precision_1: 0.9402 - recall_1: 0.8174 - f1_score: 0.8786 - val_loss: 0.6857 - val_accuracy: 0.7797 - val_precision_1: 0.8654 - val_recall_1: 0.7627 - val_f1_score: 0.7602 - lr: 6.2982e-05\n",
      "Epoch 48/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.4585 - accuracy: 0.8694 - precision_1: 0.9352 - recall_1: 0.8029 - f1_score: 0.8701\n",
      "Epoch 48: val_loss did not improve from 0.61097\n",
      "165/165 [==============================] - 18s 102ms/step - loss: 0.4585 - accuracy: 0.8694 - precision_1: 0.9352 - recall_1: 0.8029 - f1_score: 0.8701 - val_loss: 0.6302 - val_accuracy: 0.8136 - val_precision_1: 0.8846 - val_recall_1: 0.7797 - val_f1_score: 0.8106 - lr: 6.2353e-05\n",
      "Epoch 49/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.4128 - accuracy: 0.8936 - precision_1: 0.9485 - recall_1: 0.8235 - f1_score: 0.8934\n",
      "Epoch 49: val_loss did not improve from 0.61097\n",
      "165/165 [==============================] - 22s 122ms/step - loss: 0.4128 - accuracy: 0.8936 - precision_1: 0.9485 - recall_1: 0.8235 - f1_score: 0.8934 - val_loss: 0.6459 - val_accuracy: 0.8136 - val_precision_1: 0.8846 - val_recall_1: 0.7797 - val_f1_score: 0.7931 - lr: 6.1729e-05\n",
      "Epoch 50/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.9100 - precision_1: 0.9582 - recall_1: 0.8358 - f1_score: 0.9095\n",
      "Epoch 50: val_loss did not improve from 0.61097\n",
      "165/165 [==============================] - 19s 107ms/step - loss: 0.3945 - accuracy: 0.9069 - precision_1: 0.9569 - recall_1: 0.8331 - f1_score: 0.9067 - val_loss: 0.6539 - val_accuracy: 0.8305 - val_precision_1: 0.8519 - val_recall_1: 0.7797 - val_f1_score: 0.8260 - lr: 6.1112e-05\n",
      "Epoch 51/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.4181 - accuracy: 0.8759 - precision_1: 0.9423 - recall_1: 0.8139 - f1_score: 0.8767\n",
      "Epoch 51: val_loss improved from 0.61097 to 0.59725, saving model to vgg_16_best_model.hdf5\n",
      "165/165 [==============================] - 18s 103ms/step - loss: 0.4165 - accuracy: 0.8767 - precision_1: 0.9427 - recall_1: 0.8150 - f1_score: 0.8774 - val_loss: 0.5972 - val_accuracy: 0.8305 - val_precision_1: 0.8868 - val_recall_1: 0.7966 - val_f1_score: 0.8115 - lr: 6.0501e-05\n",
      "Epoch 52/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.4615 - accuracy: 0.8662 - precision_1: 0.9505 - recall_1: 0.7944 - f1_score: 0.8675\n",
      "Epoch 52: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 18s 102ms/step - loss: 0.4607 - accuracy: 0.8658 - precision_1: 0.9494 - recall_1: 0.7944 - f1_score: 0.8672 - val_loss: 0.6928 - val_accuracy: 0.7627 - val_precision_1: 0.8462 - val_recall_1: 0.7458 - val_f1_score: 0.7439 - lr: 5.9896e-05\n",
      "Epoch 53/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3923 - accuracy: 0.8972 - precision_1: 0.9579 - recall_1: 0.8247 - f1_score: 0.8973\n",
      "Epoch 53: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 20s 113ms/step - loss: 0.3923 - accuracy: 0.8972 - precision_1: 0.9579 - recall_1: 0.8247 - f1_score: 0.8973 - val_loss: 0.7216 - val_accuracy: 0.7797 - val_precision_1: 0.8302 - val_recall_1: 0.7458 - val_f1_score: 0.7751 - lr: 5.9297e-05\n",
      "Epoch 54/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3791 - accuracy: 0.8948 - precision_1: 0.9505 - recall_1: 0.8356 - f1_score: 0.8960\n",
      "Epoch 54: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 21s 116ms/step - loss: 0.3791 - accuracy: 0.8948 - precision_1: 0.9505 - recall_1: 0.8356 - f1_score: 0.8960 - val_loss: 0.7400 - val_accuracy: 0.7797 - val_precision_1: 0.8600 - val_recall_1: 0.7288 - val_f1_score: 0.7718 - lr: 5.8704e-05\n",
      "Epoch 55/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3974 - accuracy: 0.8984 - precision_1: 0.9332 - recall_1: 0.8271 - f1_score: 0.8992\n",
      "Epoch 55: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 21s 119ms/step - loss: 0.3974 - accuracy: 0.8984 - precision_1: 0.9332 - recall_1: 0.8271 - f1_score: 0.8992 - val_loss: 0.7016 - val_accuracy: 0.7797 - val_precision_1: 0.8431 - val_recall_1: 0.7288 - val_f1_score: 0.7773 - lr: 5.8117e-05\n",
      "Epoch 56/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3933 - accuracy: 0.8924 - precision_1: 0.9510 - recall_1: 0.8440 - f1_score: 0.8936\n",
      "Epoch 56: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 19s 100ms/step - loss: 0.3933 - accuracy: 0.8924 - precision_1: 0.9510 - recall_1: 0.8440 - f1_score: 0.8936 - val_loss: 0.7549 - val_accuracy: 0.7797 - val_precision_1: 0.8077 - val_recall_1: 0.7119 - val_f1_score: 0.7806 - lr: 5.7535e-05\n",
      "Epoch 57/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3972 - accuracy: 0.8912 - precision_1: 0.9416 - recall_1: 0.8186 - f1_score: 0.8913\n",
      "Epoch 57: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 18s 99ms/step - loss: 0.3972 - accuracy: 0.8912 - precision_1: 0.9416 - recall_1: 0.8186 - f1_score: 0.8913 - val_loss: 0.8032 - val_accuracy: 0.7627 - val_precision_1: 0.8077 - val_recall_1: 0.7119 - val_f1_score: 0.7608 - lr: 5.6960e-05\n",
      "Epoch 58/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.4010 - accuracy: 0.8954 - precision_1: 0.9398 - recall_1: 0.8358 - f1_score: 0.8961\n",
      "Epoch 58: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 18s 99ms/step - loss: 0.4001 - accuracy: 0.8960 - precision_1: 0.9401 - recall_1: 0.8356 - f1_score: 0.8968 - val_loss: 0.7546 - val_accuracy: 0.7458 - val_precision_1: 0.8367 - val_recall_1: 0.6949 - val_f1_score: 0.7438 - lr: 5.6391e-05\n",
      "Epoch 59/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.3783 - accuracy: 0.8990 - precision_1: 0.9520 - recall_1: 0.8443 - f1_score: 0.8989\n",
      "Epoch 59: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 19s 103ms/step - loss: 0.3776 - accuracy: 0.8996 - precision_1: 0.9523 - recall_1: 0.8440 - f1_score: 0.8998 - val_loss: 0.8092 - val_accuracy: 0.7288 - val_precision_1: 0.8511 - val_recall_1: 0.6780 - val_f1_score: 0.7239 - lr: 5.5827e-05\n",
      "Epoch 60/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3585 - accuracy: 0.9057 - precision_1: 0.9577 - recall_1: 0.8489 - f1_score: 0.9059\n",
      "Epoch 60: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 18s 104ms/step - loss: 0.3585 - accuracy: 0.9057 - precision_1: 0.9577 - recall_1: 0.8489 - f1_score: 0.9059 - val_loss: 0.8224 - val_accuracy: 0.7627 - val_precision_1: 0.8367 - val_recall_1: 0.6949 - val_f1_score: 0.7618 - lr: 5.5268e-05\n",
      "Epoch 61/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.3307 - accuracy: 0.9173 - precision_1: 0.9628 - recall_1: 0.8491 - f1_score: 0.9176\n",
      "Epoch 61: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 18s 101ms/step - loss: 0.3293 - accuracy: 0.9178 - precision_1: 0.9630 - recall_1: 0.8501 - f1_score: 0.9180 - val_loss: 0.8145 - val_accuracy: 0.7627 - val_precision_1: 0.8571 - val_recall_1: 0.7119 - val_f1_score: 0.7574 - lr: 5.4716e-05\n",
      "Epoch 62/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.4184 - accuracy: 0.8718 - precision_1: 0.9409 - recall_1: 0.8271 - f1_score: 0.8717\n",
      "Epoch 62: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 18s 104ms/step - loss: 0.4184 - accuracy: 0.8718 - precision_1: 0.9409 - recall_1: 0.8271 - f1_score: 0.8717 - val_loss: 0.8302 - val_accuracy: 0.7627 - val_precision_1: 0.8077 - val_recall_1: 0.7119 - val_f1_score: 0.7599 - lr: 5.4169e-05\n",
      "Epoch 63/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3432 - accuracy: 0.9081 - precision_1: 0.9667 - recall_1: 0.8416 - f1_score: 0.9085\n",
      "Epoch 63: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 22s 127ms/step - loss: 0.3432 - accuracy: 0.9081 - precision_1: 0.9667 - recall_1: 0.8416 - f1_score: 0.9085 - val_loss: 0.8215 - val_accuracy: 0.7288 - val_precision_1: 0.8400 - val_recall_1: 0.7119 - val_f1_score: 0.7055 - lr: 5.3627e-05\n",
      "Epoch 64/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3619 - accuracy: 0.9021 - precision_1: 0.9592 - recall_1: 0.8525 - f1_score: 0.9024\n",
      "Epoch 64: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 23s 134ms/step - loss: 0.3619 - accuracy: 0.9021 - precision_1: 0.9592 - recall_1: 0.8525 - f1_score: 0.9024 - val_loss: 0.8100 - val_accuracy: 0.7797 - val_precision_1: 0.8400 - val_recall_1: 0.7119 - val_f1_score: 0.7744 - lr: 5.3091e-05\n",
      "Epoch 65/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3340 - accuracy: 0.9081 - precision_1: 0.9621 - recall_1: 0.8585 - f1_score: 0.9078\n",
      "Epoch 65: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 19s 104ms/step - loss: 0.3340 - accuracy: 0.9081 - precision_1: 0.9621 - recall_1: 0.8585 - f1_score: 0.9078 - val_loss: 0.8565 - val_accuracy: 0.7627 - val_precision_1: 0.8269 - val_recall_1: 0.7288 - val_f1_score: 0.7514 - lr: 5.2560e-05\n",
      "Epoch 66/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.3037 - accuracy: 0.9294 - precision_1: 0.9636 - recall_1: 0.8698 - f1_score: 0.9296\n",
      "Epoch 66: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 18s 104ms/step - loss: 0.3026 - accuracy: 0.9299 - precision_1: 0.9639 - recall_1: 0.8706 - f1_score: 0.9300 - val_loss: 0.8838 - val_accuracy: 0.7627 - val_precision_1: 0.8039 - val_recall_1: 0.6949 - val_f1_score: 0.7369 - lr: 5.2034e-05\n",
      "Epoch 67/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.3554 - accuracy: 0.8893 - precision_1: 0.9471 - recall_1: 0.8491 - f1_score: 0.8898\n",
      "Epoch 67: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 19s 106ms/step - loss: 0.3560 - accuracy: 0.8888 - precision_1: 0.9460 - recall_1: 0.8476 - f1_score: 0.8895 - val_loss: 1.1179 - val_accuracy: 0.7288 - val_precision_1: 0.8235 - val_recall_1: 0.7119 - val_f1_score: 0.7114 - lr: 5.1514e-05\n",
      "Epoch 68/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3530 - accuracy: 0.8972 - precision_1: 0.9536 - recall_1: 0.8440 - f1_score: 0.8977\n",
      "Epoch 68: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 18s 101ms/step - loss: 0.3530 - accuracy: 0.8972 - precision_1: 0.9536 - recall_1: 0.8440 - f1_score: 0.8977 - val_loss: 1.3844 - val_accuracy: 0.7458 - val_precision_1: 0.8235 - val_recall_1: 0.7119 - val_f1_score: 0.7392 - lr: 5.0999e-05\n",
      "Epoch 69/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.3303 - accuracy: 0.9112 - precision_1: 0.9674 - recall_1: 0.8662 - f1_score: 0.9118\n",
      "Epoch 69: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 19s 106ms/step - loss: 0.3357 - accuracy: 0.9093 - precision_1: 0.9675 - recall_1: 0.8646 - f1_score: 0.9099 - val_loss: 1.1900 - val_accuracy: 0.6949 - val_precision_1: 0.8039 - val_recall_1: 0.6949 - val_f1_score: 0.6835 - lr: 5.0489e-05\n",
      "Epoch 70/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3359 - accuracy: 0.9117 - precision_1: 0.9580 - recall_1: 0.8549 - f1_score: 0.9120\n",
      "Epoch 70: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 19s 106ms/step - loss: 0.3359 - accuracy: 0.9117 - precision_1: 0.9580 - recall_1: 0.8549 - f1_score: 0.9120 - val_loss: 1.5395 - val_accuracy: 0.7627 - val_precision_1: 0.8269 - val_recall_1: 0.7288 - val_f1_score: 0.7577 - lr: 4.9984e-05\n",
      "Epoch 71/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3473 - accuracy: 0.9093 - precision_1: 0.9539 - recall_1: 0.8513 - f1_score: 0.9093\n",
      "Epoch 71: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 21s 118ms/step - loss: 0.3473 - accuracy: 0.9093 - precision_1: 0.9539 - recall_1: 0.8513 - f1_score: 0.9093 - val_loss: 0.8841 - val_accuracy: 0.7458 - val_precision_1: 0.8235 - val_recall_1: 0.7119 - val_f1_score: 0.7356 - lr: 4.9484e-05\n",
      "Epoch 72/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8966 - precision_1: 0.9476 - recall_1: 0.8358 - f1_score: 0.8973\n",
      "Epoch 72: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 18s 103ms/step - loss: 0.3842 - accuracy: 0.8972 - precision_1: 0.9478 - recall_1: 0.8343 - f1_score: 0.8979 - val_loss: 0.8961 - val_accuracy: 0.7119 - val_precision_1: 0.7736 - val_recall_1: 0.6949 - val_f1_score: 0.7094 - lr: 4.8989e-05\n",
      "Epoch 73/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3892 - accuracy: 0.8839 - precision_1: 0.9420 - recall_1: 0.8247 - f1_score: 0.8841\n",
      "Epoch 73: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 19s 105ms/step - loss: 0.3892 - accuracy: 0.8839 - precision_1: 0.9420 - recall_1: 0.8247 - f1_score: 0.8841 - val_loss: 0.8378 - val_accuracy: 0.7288 - val_precision_1: 0.7843 - val_recall_1: 0.6780 - val_f1_score: 0.7249 - lr: 4.8499e-05\n",
      "Epoch 74/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.3107 - accuracy: 0.9112 - precision_1: 0.9481 - recall_1: 0.8674 - f1_score: 0.9115\n",
      "Epoch 74: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 22s 129ms/step - loss: 0.3095 - accuracy: 0.9117 - precision_1: 0.9485 - recall_1: 0.8682 - f1_score: 0.9119 - val_loss: 0.8306 - val_accuracy: 0.7797 - val_precision_1: 0.8269 - val_recall_1: 0.7288 - val_f1_score: 0.7677 - lr: 4.8014e-05\n",
      "Epoch 75/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.3294 - accuracy: 0.9039 - precision_1: 0.9531 - recall_1: 0.8662 - f1_score: 0.9040\n",
      "Epoch 75: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 18s 100ms/step - loss: 0.3279 - accuracy: 0.9045 - precision_1: 0.9535 - recall_1: 0.8670 - f1_score: 0.9047 - val_loss: 0.9297 - val_accuracy: 0.7458 - val_precision_1: 0.8235 - val_recall_1: 0.7119 - val_f1_score: 0.7286 - lr: 4.7534e-05\n",
      "Epoch 76/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3356 - accuracy: 0.9057 - precision_1: 0.9544 - recall_1: 0.8597 - f1_score: 0.9069\n",
      "Epoch 76: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 18s 105ms/step - loss: 0.3356 - accuracy: 0.9057 - precision_1: 0.9544 - recall_1: 0.8597 - f1_score: 0.9069 - val_loss: 1.1615 - val_accuracy: 0.7458 - val_precision_1: 0.8200 - val_recall_1: 0.6949 - val_f1_score: 0.7207 - lr: 4.7059e-05\n",
      "Epoch 77/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.3373 - accuracy: 0.9129 - precision_1: 0.9524 - recall_1: 0.8718 - f1_score: 0.9125\n",
      "Epoch 77: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 18s 101ms/step - loss: 0.3373 - accuracy: 0.9129 - precision_1: 0.9524 - recall_1: 0.8718 - f1_score: 0.9125 - val_loss: 0.8488 - val_accuracy: 0.7458 - val_precision_1: 0.8077 - val_recall_1: 0.7119 - val_f1_score: 0.7211 - lr: 4.6588e-05\n",
      "Epoch 78/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.2932 - accuracy: 0.9262 - precision_1: 0.9605 - recall_1: 0.8815 - f1_score: 0.9268\n",
      "Epoch 78: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 21s 121ms/step - loss: 0.2932 - accuracy: 0.9262 - precision_1: 0.9605 - recall_1: 0.8815 - f1_score: 0.9268 - val_loss: 0.7773 - val_accuracy: 0.7627 - val_precision_1: 0.8542 - val_recall_1: 0.6949 - val_f1_score: 0.7377 - lr: 4.6122e-05\n",
      "Epoch 79/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.2650 - accuracy: 0.9311 - precision_1: 0.9646 - recall_1: 0.8888 - f1_score: 0.9317\n",
      "Epoch 79: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 18s 103ms/step - loss: 0.2650 - accuracy: 0.9311 - precision_1: 0.9646 - recall_1: 0.8888 - f1_score: 0.9317 - val_loss: 0.8343 - val_accuracy: 0.7458 - val_precision_1: 0.8333 - val_recall_1: 0.6780 - val_f1_score: 0.7437 - lr: 4.5661e-05\n",
      "Epoch 80/100\n",
      "166/165 [==============================] - ETA: 0s - loss: 0.2817 - accuracy: 0.9238 - precision_1: 0.9594 - recall_1: 0.8851 - f1_score: 0.9237\n",
      "Epoch 80: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 19s 109ms/step - loss: 0.2817 - accuracy: 0.9238 - precision_1: 0.9594 - recall_1: 0.8851 - f1_score: 0.9237 - val_loss: 0.8570 - val_accuracy: 0.7627 - val_precision_1: 0.8200 - val_recall_1: 0.6949 - val_f1_score: 0.7607 - lr: 4.5204e-05\n",
      "Epoch 81/100\n",
      "165/165 [============================>.] - ETA: 0s - loss: 0.2959 - accuracy: 0.9148 - precision_1: 0.9623 - recall_1: 0.8686 - f1_score: 0.9151\n",
      "Epoch 81: val_loss did not improve from 0.59725\n",
      "165/165 [==============================] - 19s 104ms/step - loss: 0.2978 - accuracy: 0.9141 - precision_1: 0.9611 - recall_1: 0.8670 - f1_score: 0.9145 - val_loss: 0.8464 - val_accuracy: 0.7797 - val_precision_1: 0.8269 - val_recall_1: 0.7288 - val_f1_score: 0.7601 - lr: 4.4752e-05\n",
      "Epoch 81: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=\n",
    "         train_generator.samples/train_generator.batch_size,\n",
    "      epochs=100,\n",
    "      validation_data=validation_generator, \n",
    "      validation_steps=\n",
    "         validation_generator.samples/validation_generator.batch_size,\n",
    "      verbose=1,\n",
    "      workers = 10,\n",
    "      use_multiprocessing = True,\n",
    "      callbacks = [checkpoint, es, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6174cdcd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "6174cdcd",
    "outputId": "b2e54a9e-81c0-43cf-89a1-a90d581c22e2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the function to illustrate accuracy and loss\n",
    "visualize_results(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d99b2469",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d99b2469",
    "outputId": "fca4cef5-6746-4e82-a9fd-d25d57999f68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 290 non-validated image filenames belonging to 20 classes.\n",
      "Loading model vgg_16_best_model.hdf5\n",
      "58/58 [==============================] - 3s 42ms/step - loss: 0.8152 - accuracy: 0.7655 - precision_1: 0.8137 - recall_1: 0.7379 - f1_score: 0.7633\n",
      "Test Loss 0.8151741027832031\n",
      "Test Accuracy 0.7655172348022461\n",
      "Test Precision 0.8136882185935974\n",
      "Test Recall 0.7379310131072998\n",
      "Test F1 Score 0.7632772\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "validate_filenames=False,\n",
    "dataframe = test_df,\n",
    "directory = '',\n",
    "x_col = 'Images',\n",
    "y_col = 'Class',\n",
    "class_mode = 'categorical',\n",
    "batch_size = 5,\n",
    "target_size=(224,224))\n",
    "\n",
    "model = load_model(filepath)\n",
    "print(f\"Loading model {filepath}\")\n",
    "loss, accuracy, precision, recall, f1_score = model.evaluate(test_generator, verbose = 1)\n",
    "print(\"Test Loss\", loss)\n",
    "print(\"Test Accuracy\", accuracy)\n",
    "print(\"Test Precision\", precision)\n",
    "print(\"Test Recall\", recall)\n",
    "print(\"Test F1 Score\", f1_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fa86ce",
   "metadata": {
    "id": "044469ef"
   },
   "source": [
    "### v. Report Precision, Recall, and F1 score for your model. Remember that this is a multi-class classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0eadd7",
   "metadata": {},
   "source": [
    "> Precision Recall F1 Score for both models have been reported above after each of the individual model runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d799f57",
   "metadata": {
    "id": "3d799f57"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
